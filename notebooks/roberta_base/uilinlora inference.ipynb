{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb563ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff83153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91bb00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=torch.inf)  # Display all elements\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f4c491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BASE_ID = \"roberta-base\"\n",
    "base = AutoModelForSequenceClassification.from_pretrained(\n",
    "           BASE_ID, num_labels=2, device_map=\"auto\")\n",
    "\n",
    "model = PeftModel.from_pretrained(base, \"uilinlora_adapter\").to(device)\n",
    "tok = AutoTokenizer.from_pretrained(\"uilinlora_adapter\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fea38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52cd913b0254625801b776679ceb8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest raw sentence: 67 tokens\n"
     ]
    }
   ],
   "source": [
    "model.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "# ---------- data ----------\n",
    "raw_ds = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    natural   = tok(batch[\"sentence\"], add_special_tokens=True)\n",
    "    true_lens = [len(ids) for ids in natural[\"input_ids\"]]\n",
    "\n",
    "    padded = tok(\n",
    "        batch[\"sentence\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    padded[\"real_length\"] = true_lens\n",
    "    return padded\n",
    "\n",
    "tokenized_ds = raw_ds.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=[\"sentence\", \"idx\"]\n",
    ")\n",
    "\n",
    "# rename + set Torch format\n",
    "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
    "tokenized_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\", \"real_length\"],\n",
    ")\n",
    "\n",
    "# ---------- stats ----------\n",
    "max_len = max(tokenized_ds[\"train\"][\"real_length\"])\n",
    "print(f\"Longest raw sentence: {max_len} tokens\")\n",
    "\n",
    "\n",
    "# ---------- data ----------\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "def tokenize_function(example):\n",
    "    return tok(example[\"sentence\"], truncation=True, padding=\"max_length\", max_length=100)\n",
    "\n",
    "# Tokenize the entire dataset\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "del raw_datasets\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a71ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:08<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5103211009174312}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=32)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "        logits = model(**batch).logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(batch[\"labels\"].cpu())\n",
    "\n",
    "preds = torch.cat(all_preds).numpy()\n",
    "labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "print(accuracy.compute(predictions=preds, references=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "044b4105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UILinLoRALayer(Linear(in_features=768, out_features=768, bias=True))\n"
     ]
    }
   ],
   "source": [
    "adapter_layer = model.base_model.model.classifier.dense\n",
    "print(adapter_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3bfe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "adapter_name = adapter_layer.active_adapters[0]\n",
    "print(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbdcf04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sf': 1.0, 'pos': True}\n",
      "torch.Size([768, 128])\n",
      "torch.Size([128, 768])\n",
      "torch.Size([128])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "U  = getattr(adapter_layer, f\"{adapter_name}_U\")         # (out, r)\n",
    "V  = getattr(adapter_layer, f\"{adapter_name}_V\")         # (r, in)\n",
    "Σ  = adapter_layer.uilinlora_sigma[adapter_name]         # (r,)\n",
    "D  = adapter_layer.uilinlora_D[adapter_name]             # (in,)\n",
    "E  = adapter_layer.uilinlora_E[adapter_name]             # (out,)\n",
    "print(adapter_layer._meta[adapter_name])\n",
    "\n",
    "print(U.shape)\n",
    "print(V.shape)\n",
    "print(Σ.shape)\n",
    "print(D.shape)\n",
    "print(E.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4922a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07, 1.0000e-07,\n",
      "        1.0000e-07, 1.0000e-07], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d92cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): UILinLoRAModel(\n",
      "    (model): RobertaForSequenceClassification(\n",
      "      (roberta): RobertaModel(\n",
      "        (embeddings): RobertaEmbeddings(\n",
      "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "          (token_type_embeddings): Embedding(1, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): RobertaEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-11): 12 x RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (classifier): RobertaClassificationHead(\n",
      "        (dense): UILinLoRALayer(Linear(in_features=768, out_features=768, bias=True))\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052ccc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00d68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f08b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e0503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e83fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non trained model accuracy 0.4919\n",
    "# For r=128 one epoch lr 3e-3 accuracy 0.932\n",
    "# For r=128 two epochs lr 3e-3 accuracy 0.939"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guyb_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
