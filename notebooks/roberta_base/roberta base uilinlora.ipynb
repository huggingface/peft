{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb563ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff83153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import UILinLoRAConfig, get_peft_model, PeftModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91bb00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=torch.inf)  # Display all elements\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd11a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BASE_ID = \"roberta-base\"\n",
    "tok  = AutoTokenizer.from_pretrained(BASE_ID, use_fast=True)\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "# quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_ID,\n",
    "    num_labels=2,\n",
    "    # quantization_config=quant_config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a47f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uilinlora_cfg = UILinLoRAConfig(\n",
    "        target_modules=[\"query\", \"value\"],\n",
    "        uilinlora_alpha=1.0,\n",
    "        uilinlora_dropout=0.0,\n",
    "        fan_in_fan_out=False,\n",
    "        rank=128)\n",
    "model = get_peft_model(base_model, uilinlora_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bf9ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4c4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.classifier.dense.weight\n",
      "torch.Size([768, 768])\n",
      "base_model.model.classifier.dense.bias\n",
      "torch.Size([768])\n",
      "base_model.model.classifier.out_proj.weight\n",
      "torch.Size([2, 768])\n",
      "base_model.model.classifier.out_proj.bias\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(name)\n",
    "        print(param.shape)\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5e3748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss requires grad? True\n",
      "loss grad_fn? <NllLossBackward0 object at 0x7f1ac7dceb60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:446: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model.train()\n",
    "# batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "# out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "\n",
    "# print(\"loss requires grad?\", out.loss.requires_grad)\n",
    "# print(\"loss grad_fn?\", out.loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53dbb37f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stop\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6dcae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): UILinLoRAModel(\n",
      "    (model): RobertaForSequenceClassification(\n",
      "      (roberta): RobertaModel(\n",
      "        (embeddings): RobertaEmbeddings(\n",
      "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "          (token_type_embeddings): Embedding(1, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): RobertaEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-11): 12 x RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): UILinLoRALayer(Linear(in_features=768, out_features=768, bias=True))\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): UILinLoRALayer(Linear(in_features=768, out_features=768, bias=True))\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (classifier): RobertaClassificationHead(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e329c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.0.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.0.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.1.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.1.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.2.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.2.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.3.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.3.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.4.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.4.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.5.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.5.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.6.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.6.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.7.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.7.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.8.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.8.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.9.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.9.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.10.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.10.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.11.attention.self.query\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n",
      "\n",
      "Adapter module: base_model.model.roberta.encoder.layer.11.attention.self.value\n",
      "  Adapter name: default\n",
      "    Î£ shape: torch.Size([128])\n",
      "    D shape: torch.Size([768])\n",
      "    E shape: torch.Size([768])\n",
      "    U shape: torch.Size([768, 128])\n",
      "    V shape: torch.Size([128, 768])\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if hasattr(module, \"uilinlora_sigma\"):\n",
    "        print(f\"\\nAdapter module: {name}\")\n",
    "        for adapter_name in module.uilinlora_sigma.keys():\n",
    "            print(f\"  Adapter name: {adapter_name}\")\n",
    "            print(f\"    Î£ shape: {module.uilinlora_sigma[adapter_name].shape}\")\n",
    "            print(f\"    D shape: {module.uilinlora_D[adapter_name].shape}\")\n",
    "            print(f\"    E shape: {module.uilinlora_E[adapter_name].shape}\")\n",
    "            print(f\"    U shape: {getattr(module, f'{adapter_name}_U').shape}\")\n",
    "            print(f\"    V shape: {getattr(module, f'{adapter_name}_V').shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902b3ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.roberta.encoder.layer.0.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.uilinlora_sigma.default: torch.Size([128])\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.uilinlora_D.default: torch.Size([768])\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.uilinlora_E.default: torch.Size([768])\n",
      "base_model.model.classifier.dense.weight: torch.Size([768, 768])\n",
      "base_model.model.classifier.dense.bias: torch.Size([768])\n",
      "base_model.model.classifier.out_proj.weight: torch.Size([2, 768])\n",
      "base_model.model.classifier.out_proj.bias: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88af6dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, buf \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_buffers():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, buf in model.named_buffers():\n",
    "    print(f\"{name}: {buf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c9c456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 632,066\n",
      "Total parameters: 124,687,106\n",
      "Trainable %: 0.50692170%\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Trainable %: {100 * trainable / total:.8f}%\")\n",
    "\n",
    "print_trainable_params(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf457d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90fea38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest raw sentence: 67 tokens\n"
     ]
    }
   ],
   "source": [
    "model.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "# ---------- data ----------\n",
    "raw_ds = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    natural   = tok(batch[\"sentence\"], add_special_tokens=True)\n",
    "    true_lens = [len(ids) for ids in natural[\"input_ids\"]]\n",
    "\n",
    "    padded = tok(\n",
    "        batch[\"sentence\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    padded[\"real_length\"] = true_lens\n",
    "    return padded\n",
    "\n",
    "tokenized_ds = raw_ds.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=[\"sentence\", \"idx\"]\n",
    ")\n",
    "\n",
    "# rename + set Torch format\n",
    "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
    "tokenized_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\", \"real_length\"],\n",
    ")\n",
    "\n",
    "# ---------- stats ----------\n",
    "max_len = max(tokenized_ds[\"train\"][\"real_length\"])\n",
    "print(f\"Longest raw sentence: {max_len} tokens\")\n",
    "\n",
    "\n",
    "# ---------- data ----------\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "def tokenize_function(example):\n",
    "    return tok(example[\"sentence\"], truncation=True, padding=\"max_length\", max_length=100)\n",
    "\n",
    "# Tokenize the entire dataset\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "del raw_datasets\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eecc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- trainer ----------\n",
    "args = TrainingArguments(\n",
    "        output_dir=\"uilinlora-sst2\",\n",
    "        per_device_train_batch_size=32,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=3e-3,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=50)\n",
    "\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=tokenized_datasets[\"train\"],\n",
    "                  eval_dataset=tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b153556f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='2105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  33/2105 00:11 < 13:19, 2.59 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:814\u001b[0m, in \u001b[0;36mPeftModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    813\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_base_model()(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(\n\u001b[1;32m   1196\u001b[0m     input_ids,\n\u001b[1;32m   1197\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1198\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1199\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1200\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1201\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1202\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1203\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1204\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1205\u001b[0m )\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    833\u001b[0m     embedding_output,\n\u001b[1;32m    834\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    835\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    836\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    837\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m    838\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    839\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    840\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    841\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    842\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    843\u001b[0m )\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    522\u001b[0m         hidden_states,\n\u001b[1;32m    523\u001b[0m         attention_mask,\n\u001b[1;32m    524\u001b[0m         layer_head_mask,\n\u001b[1;32m    525\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    526\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    527\u001b[0m         past_key_value,\n\u001b[1;32m    528\u001b[0m         output_attentions,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:410\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    411\u001b[0m         hidden_states,\n\u001b[1;32m    412\u001b[0m         attention_mask,\n\u001b[1;32m    413\u001b[0m         head_mask,\n\u001b[1;32m    414\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    415\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:346\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    329\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    337\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    338\u001b[0m         hidden_states,\n\u001b[1;32m    339\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m         output_attentions,\n\u001b[1;32m    345\u001b[0m     )\n\u001b[0;32m--> 346\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    347\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f985ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "logits = predictions.predictions[1]\n",
    "preds = np.argmax(logits, axis=-1)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "tokenized_datasets[\"validation\"][\"labels\"]\n",
    "metric.compute(predictions=preds, references=tokenized_datasets[\"validation\"][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d92cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3806574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # after trainer.train()\n",
    "# adapter_dir = \"uilinlora_adapter\"\n",
    "# model.save_pretrained(adapter_dir, safe_serialization=True)  # adapter only\n",
    "# tok.save_pretrained(adapter_dir)                             # optional, for easy reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334d3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68473fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_ID = \"roberta-base\"\n",
    "# base = AutoModelForSequenceClassification.from_pretrained(\n",
    "#            BASE_ID, num_labels=2, device_map=\"auto\")\n",
    "\n",
    "# model = PeftModel.from_pretrained(base, \"uilinlora_adapter\").to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"uilinlora_adapter\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2db3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "# logits = predictions.predictions[1]\n",
    "# preds = np.argmax(logits, axis=-1)\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# tokenized_datasets[\"validation\"][\"labels\"]\n",
    "# metric.compute(predictions=preds, references=tokenized_datasets[\"validation\"][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052ccc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00d68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f08b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e0503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Debugging things\n",
    "\n",
    "# # core_model   = model.get_base_model()        # â LlamaForSequenceClassification\n",
    "# # llama_blocks = core_model.model.layers       # â ModuleList of decoder layers\n",
    "# # qproj_0      = llama_blocks[0].self_attn.q_proj\n",
    "\n",
    "# # print(type(qproj_0))          # should be your Linear4bit / Linear8bitLt\n",
    "# # print(qproj_0.weight.shape)   # should be (out, in)  e.g.  (4096, 2048)\n",
    "\n",
    "# model.train()\n",
    "# with torch.amp.autocast(\"cuda\"):\n",
    "#     batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "#     out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "\n",
    "# loss = out.loss.to(torch.float32)\n",
    "# loss.backward()\n",
    "\n",
    "\n",
    "# # Check grads manually\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad and param.grad is not None:\n",
    "#         print(f\"{name} has non-zero grad: {param.grad.abs().mean().item():.6f}\")\n",
    "\n",
    "# model.train()\n",
    "# batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "# out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "\n",
    "# print(\"loss requires grad?\", out.loss.requires_grad)\n",
    "# print(\"loss grad_fn?\", out.loss.grad_fn)\n",
    "\n",
    "# for n, p in model.named_parameters():\n",
    "#     if p.requires_grad:\n",
    "#         print(n, p.shape)\n",
    "\n",
    "#         # model.train()\n",
    "# # batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "# # out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "# # print(out.loss.grad_fn)  # should NOT be None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e83fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non trained model accuracy 0.4919\n",
    "# For r=128 one epoch lr 3e-3 accuracy 0.932\n",
    "# For r=128 two epochs lr 3e-3 accuracy 0.939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ed452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "062abb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch, evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, BitsAndBytesConfig, Trainer\n",
    ")\n",
    "from peft import UILinLoRAConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8363673",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=float(\"inf\"))\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32740fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------  custom trainer  --------------------------- #\n",
    "class UILinLoRATrainer(Trainer):\n",
    "    def __init__(self, *args, head_lr=1e-3, adapter_lr=4e-3, **kw):\n",
    "        super().__init__(*args, **kw)\n",
    "        self.head_lr, self.adapter_lr = head_lr, adapter_lr\n",
    "\n",
    "    def create_optimizer(self):                       # two learning rates\n",
    "        if self.optimizer is None:\n",
    "            head, adapter = [], []\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.requires_grad:\n",
    "                    (head if \"classifier\" in n else adapter).append(p)\n",
    "            groups = [{\"params\": head,    \"lr\": self.head_lr},\n",
    "                      {\"params\": adapter, \"lr\": self.adapter_lr}]\n",
    "            self.optimizer = torch.optim.AdamW(groups)\n",
    "        return self.optimizer\n",
    "\n",
    "# ---------------------------  helpers  --------------------------- #\n",
    "def prepare_sst2_dataset(tokenizer, max_len=128):\n",
    "    ds = load_dataset(\"glue\", \"sst2\")\n",
    "    ds = ds.map(\n",
    "        lambda ex: tokenizer(ex[\"sentence\"],\n",
    "                             truncation=True,\n",
    "                             padding=\"max_length\",\n",
    "                             max_length=max_len),\n",
    "        batched=True)\n",
    "    ds = ds.rename_column(\"label\", \"labels\")\n",
    "    ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    return ds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e6c6171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_id = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_id, use_fast=True)\n",
    "\n",
    "base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_id, num_labels=2, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "uilinlora_cfg = UILinLoRAConfig(\n",
    "        target_modules=[\"query\", \"value\"],\n",
    "        rank=128,\n",
    "        uilinlora_alpha=1.0,\n",
    "        uilinlora_dropout=0.0,\n",
    "        fan_in_fan_out=False,\n",
    "        init_uilinlora_weights=True,\n",
    "        task_type=TaskType.SEQ_CLS)\n",
    "# model = get_peft_model(base, uilinlora_cfg)\n",
    "\n",
    "# uilinlora_cfg = UILinLoRAConfig(\n",
    "#     r=8,                              # LoRA rank\n",
    "#     lora_alpha=16,                   # Scaling factor\n",
    "#     target_modules=[\"query\", \"value\"],  # Module names to inject LoRA into (for RoBERTa/BERT)\n",
    "#     lora_dropout=0.1,                # Dropout applied to LoRA layers during training\n",
    "#     bias=\"none\",                     # \"none\", \"all\", or \"lora_only\"\n",
    "#     task_type=TaskType.SEQ_CLS      # Task type: SEQ_CLS = sequence classification\n",
    "# )\n",
    "\n",
    "model = get_peft_model(base, uilinlora_cfg)\n",
    "model.classifier.requires_grad_(True)   # make head trainable\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2e478e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_sst2_dataset(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa5c26c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/guyb_env2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ð¤ Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693457</td>\n",
       "      <td>0.123456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692987</td>\n",
       "      <td>0.123456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> compute_metrics called <<<\n",
      "type(output): <class 'numpy.ndarray'>\n",
      "output shape: (872, 2)\n",
      "labels type: <class 'numpy.ndarray'>\n",
      "labels shape: (872,)\n",
      ">>> compute_metrics called <<<\n",
      "type(output): <class 'numpy.ndarray'>\n",
      "output shape: (872, 2)\n",
      "labels type: <class 'numpy.ndarray'>\n",
      "labels shape: (872,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> compute_metrics called <<<\n",
      "type(output): <class 'numpy.ndarray'>\n",
      "output shape: (872, 2)\n",
      "labels type: <class 'numpy.ndarray'>\n",
      "labels shape: (872,)\n",
      "Best-epoch accuracy: 0.123456\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"uilinlora-roberta-base-sst2\",\n",
    "    per_device_train_batch_size=64,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.06,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    print(\">>> compute_metrics called <<<\")\n",
    "\n",
    "    output, labels = eval_pred\n",
    "\n",
    "    print(\"type(output):\", type(output))\n",
    "    print(\"output shape:\", output.shape if hasattr(output, \"shape\") else \"no shape\")\n",
    "    print(\"labels type:\", type(labels))\n",
    "    print(\"labels shape:\", labels.shape if hasattr(labels, \"shape\") else \"no shape\")\n",
    "\n",
    "    return {\"eval_accuracy\": 0.123456}  # dummy value to ensure metric is returned\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=data[\"train\"].select(range(500)),\n",
    "    eval_dataset=data[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # head_lr=1e-3,\n",
    "    # adapter_lr=4e-3,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"Best-epoch accuracy:\",\n",
    "        trainer.evaluate()[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283056bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'labels', 'idx', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 872\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5c9160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "print(trainer.evaluate().keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd69eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a47eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: PredictionOutput(predictions=(array([0.54974294, 0.5569541 , 0.5817625 , 0.58381367, 0.56774193,\n",
      "       0.5726411 , 0.53230274, 0.5903519 , 0.6318204 , 0.5852609 ,\n",
      "       0.6440132 , 0.6711867 , 0.5880575 , 0.5995588 , 0.66562164,\n",
      "       0.54330385, 0.54622316, 0.6644735 , 0.5960767 , 0.6308874 ,\n",
      "       0.6160513 , 0.62608516, 0.6061301 , 0.61669475, 0.6227592 ,\n",
      "       0.6202483 , 0.63846993, 0.61098   , 0.6022206 , 0.5886936 ,\n",
      "       0.5375526 , 0.6374905 , 0.5742527 , 0.59934634, 0.62058896,\n",
      "       0.6051544 , 0.62632877, 0.57997006, 0.52677023, 0.54231435,\n",
      "       0.62219393, 0.63591254, 0.56213444, 0.5444094 , 0.5546863 ,\n",
      "       0.55685973, 0.57151675, 0.60551995, 0.57812214, 0.59635806,\n",
      "       0.64679545, 0.56645155, 0.61685014, 0.55208635, 0.53913295,\n",
      "       0.5945992 , 0.5503514 , 0.56540185, 0.57217705, 0.579527  ,\n",
      "       0.56046504, 0.60466975, 0.54691017, 0.55767715, 0.654204  ,\n",
      "       0.6263826 , 0.55782646, 0.60765135, 0.64373773, 0.5305957 ,\n",
      "       0.58095646, 0.64743847, 0.56963843, 0.5773088 , 0.5728621 ,\n",
      "       0.5738269 , 0.5794265 , 0.6251308 , 0.53878224, 0.6099458 ,\n",
      "       0.5186021 , 0.5736211 , 0.61480033, 0.6679586 , 0.6285387 ,\n",
      "       0.6345168 , 0.6300371 , 0.661174  , 0.51386744, 0.5430286 ,\n",
      "       0.55772585, 0.5440095 , 0.5953837 , 0.5667267 , 0.59172356,\n",
      "       0.57532495, 0.5576235 , 0.602877  , 0.62348807, 0.58959925,\n",
      "       0.58064127, 0.58282757, 0.5790642 , 0.5460884 , 0.5855036 ,\n",
      "       0.6071606 , 0.6926001 , 0.67082936, 0.61204225], dtype=float32), array([[-0.14732826,  0.38125375],\n",
      "       [ 0.19873707,  0.03398804],\n",
      "       [-0.10788388,  0.3297962 ],\n",
      "       ...,\n",
      "       [ 0.01727707,  0.18945022],\n",
      "       [ 0.13590547,  0.0878715 ],\n",
      "       [-0.15079927,  0.36181062]], dtype=float32)), label_ids=None, metrics={'test_runtime': 15.3014, 'test_samples_per_second': 56.988, 'test_steps_per_second': 7.124})\n"
     ]
    }
   ],
   "source": [
    "output = trainer.predict(data[\"validation\"])\n",
    "print(\"Predictions:\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guyb_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
