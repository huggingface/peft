{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb563ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff83153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "# from datasets import load_dataset\n",
    "# from peft import UILinLoRAConfig, get_peft_model, PeftModel\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91bb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(threshold=torch.inf)  # Display all elements\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd11a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_ID = \"roberta-base\"\n",
    "# tok  = AutoTokenizer.from_pretrained(BASE_ID, use_fast=True)\n",
    "\n",
    "# quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "# # quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "# base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     BASE_ID,\n",
    "#     num_labels=2,\n",
    "#     # quantization_config=quant_config,\n",
    "#     device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a47f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uilinlora_cfg = UILinLoRAConfig(\n",
    "#         target_modules=[\"query\", \"value\"],\n",
    "#         uilinlora_alpha=1.0,\n",
    "#         uilinlora_dropout=0.0,\n",
    "#         fan_in_fan_out=False,\n",
    "#         rank=128)\n",
    "# model = get_peft_model(base_model, uilinlora_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39bf9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.classifier.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d4c4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if \"classifier\" in name:\n",
    "#         print(name)\n",
    "#         print(param.shape)\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5e3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "# out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "\n",
    "# print(\"loss requires grad?\", out.loss.requires_grad)\n",
    "# print(\"loss grad_fn?\", out.loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53dbb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e329c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if hasattr(module, \"uilinlora_sigma\"):\n",
    "#         print(f\"\\nAdapter module: {name}\")\n",
    "#         for adapter_name in module.uilinlora_sigma.keys():\n",
    "#             print(f\"  Adapter name: {adapter_name}\")\n",
    "#             print(f\"    Σ shape: {module.uilinlora_sigma[adapter_name].shape}\")\n",
    "#             print(f\"    D shape: {module.uilinlora_D[adapter_name].shape}\")\n",
    "#             print(f\"    E shape: {module.uilinlora_E[adapter_name].shape}\")\n",
    "#             print(f\"    U shape: {getattr(module, f'{adapter_name}_U').shape}\")\n",
    "#             print(f\"    V shape: {getattr(module, f'{adapter_name}_V').shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "902b3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88af6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, buf in model.named_buffers():\n",
    "#     print(f\"{name}: {buf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c9c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_trainable_params(model):\n",
    "#     total = 0\n",
    "#     trainable = 0\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if \"classifier\" in name:\n",
    "#             continue\n",
    "#         total += param.numel()\n",
    "#         if param.requires_grad:\n",
    "#             trainable += param.numel()\n",
    "#     print(f\"Trainable parameters (excluding classifier): {trainable:,}\")\n",
    "#     print(f\"Total parameters (excluding classifier): {total:,}\")\n",
    "#     print(f\"Trainable %: {100 * trainable / total:.8f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5749656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_trainable_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf457d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acfaae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "# # ---------- data ----------\n",
    "# raw_ds = load_dataset(\"glue\", \"cola\")\n",
    "\n",
    "# def tok_f(ex):\n",
    "#     return tok(\n",
    "#         ex[\"sentence\"],\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=128\n",
    "#     )\n",
    "\n",
    "# cola_ds = load_dataset(\"glue\", \"cola\")\n",
    "# cola_ds = cola_ds.map(tok_f, batched=True)\n",
    "# cola_ds = cola_ds.rename_column(\"label\", \"labels\")\n",
    "# cola_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90fea38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # def tokenize(batch):\n",
    "# #     natural   = tok(batch[\"sentence\"], add_special_tokens=True)\n",
    "# #     true_lens = [len(ids) for ids in natural[\"input_ids\"]]\n",
    "\n",
    "# #     padded = tok(\n",
    "# #         batch[\"sentence\"],\n",
    "# #         truncation=True,\n",
    "# #         padding=\"max_length\",\n",
    "# #         max_length=128,\n",
    "# #     )\n",
    "\n",
    "# #     padded[\"real_length\"] = true_lens\n",
    "# #     return padded\n",
    "\n",
    "# # tokenized_ds = raw_ds.map(\n",
    "# #     tokenize,\n",
    "# #     batched=True,\n",
    "# #     remove_columns=[\"sentence\", \"idx\"]\n",
    "# # )\n",
    "\n",
    "# # # rename + set Torch format\n",
    "# # tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
    "# # tokenized_ds.set_format(\n",
    "# #     type=\"torch\",\n",
    "# #     columns=[\"input_ids\", \"attention_mask\", \"labels\", \"real_length\"],\n",
    "# # )\n",
    "\n",
    "# # # ---------- stats ----------\n",
    "# # max_len = max(tokenized_ds[\"train\"][\"real_length\"])\n",
    "# # print(f\"Longest raw sentence: {max_len} tokens\")\n",
    "\n",
    "\n",
    "# # # ---------- data ----------\n",
    "# # raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "# # def tokenize_function(example):\n",
    "# #     return tok(example[\"sentence\"], truncation=True, padding=\"max_length\", max_length=100)\n",
    "\n",
    "# # # Tokenize the entire dataset\n",
    "# # tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "# # del raw_datasets\n",
    "# # tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "# # tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eecc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- trainer ----------\n",
    "# args = TrainingArguments(\n",
    "#         output_dir=\"uilinlora-cola\",\n",
    "#         per_device_train_batch_size=32,\n",
    "#         num_train_epochs=1,\n",
    "#         learning_rate=3e-3,\n",
    "#         eval_strategy=\"epoch\",\n",
    "#         save_strategy=\"no\",\n",
    "#         logging_steps=50)\n",
    "\n",
    "\n",
    "# trainer = Trainer(model=model,\n",
    "#                   args=args,\n",
    "#                   train_dataset=tokenized_datasets[\"train\"],\n",
    "#                   eval_dataset=tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b153556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f985ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df8f8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "# logits = predictions.predictions[1]\n",
    "# preds = np.argmax(logits, axis=-1)\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# tokenized_datasets[\"validation\"][\"labels\"]\n",
    "# metric.compute(predictions=preds, references=tokenized_datasets[\"validation\"][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7d92cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3806574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # after trainer.train()\n",
    "# adapter_dir = \"uilinlora_adapter\"\n",
    "# model.save_pretrained(adapter_dir, safe_serialization=True)  # adapter only\n",
    "# tok.save_pretrained(adapter_dir)                             # optional, for easy reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2334d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68473fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9ae3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_ID = \"roberta-base\"\n",
    "# base = AutoModelForSequenceClassification.from_pretrained(\n",
    "#            BASE_ID, num_labels=2, device_map=\"auto\")\n",
    "\n",
    "# model = PeftModel.from_pretrained(base, \"uilinlora_adapter\").to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"uilinlora_adapter\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e2db3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "# logits = predictions.predictions[1]\n",
    "# preds = np.argmax(logits, axis=-1)\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# tokenized_datasets[\"validation\"][\"labels\"]\n",
    "# metric.compute(predictions=preds, references=tokenized_datasets[\"validation\"][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f052ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd00d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14f08b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be6e0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fff9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Debugging things\n",
    "\n",
    "# # core_model   = model.get_base_model()        # → LlamaForSequenceClassification\n",
    "# # llama_blocks = core_model.model.layers       # → ModuleList of decoder layers\n",
    "# # qproj_0      = llama_blocks[0].self_attn.q_proj\n",
    "\n",
    "# # print(type(qproj_0))          # should be your Linear4bit / Linear8bitLt\n",
    "# # print(qproj_0.weight.shape)   # should be (out, in)  e.g.  (4096, 2048)\n",
    "\n",
    "# model.train()\n",
    "# with torch.amp.autocast(\"cuda\"):\n",
    "#     batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "#     out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "\n",
    "# loss = out.loss.to(torch.float32)\n",
    "# loss.backward()\n",
    "\n",
    "\n",
    "# # Check grads manually\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad and param.grad is not None:\n",
    "#         print(f\"{name} has non-zero grad: {param.grad.abs().mean().item():.6f}\")\n",
    "\n",
    "# model.train()\n",
    "# batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "# out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "\n",
    "# print(\"loss requires grad?\", out.loss.requires_grad)\n",
    "# print(\"loss grad_fn?\", out.loss.grad_fn)\n",
    "\n",
    "# for n, p in model.named_parameters():\n",
    "#     if p.requires_grad:\n",
    "#         print(n, p.shape)\n",
    "\n",
    "#         # model.train()\n",
    "# # batch = tok([\"hello\"], return_tensors=\"pt\").to(0)\n",
    "# # out = model(**batch, labels=torch.tensor([1]).to(0))\n",
    "# # print(out.loss.grad_fn)  # should NOT be None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35e83fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non trained model accuracy 0.4919\n",
    "# For r=128 one epoch lr 3e-3 accuracy 0.932\n",
    "# For r=128 two epochs lr 3e-3 accuracy 0.939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "975ed452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "062abb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch, evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, BitsAndBytesConfig, Trainer\n",
    ")\n",
    "from peft import UILinLoRAConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8363673",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=float(\"inf\"))\n",
    "matthews = evaluate.load(\"matthews_correlation\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    result = matthews.compute(predictions=preds, references=labels)\n",
    "    print(\"MCC result:\", result)\n",
    "    return result\n",
    "\n",
    "# accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32740fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------  custom trainer  --------------------------- #\n",
    "class UILinLoRATrainer(Trainer):\n",
    "    def __init__(self, *args, head_lr=1e-3, adapter_lr=4e-3, **kw):\n",
    "        super().__init__(*args, **kw)\n",
    "        self.head_lr, self.adapter_lr = head_lr, adapter_lr\n",
    "\n",
    "    def create_optimizer(self):                       # two learning rates\n",
    "        if self.optimizer is None:\n",
    "            head, adapter = [], []\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.requires_grad:\n",
    "                    (head if \"classifier\" in n else adapter).append(p)\n",
    "            groups = [{\"params\": head,    \"lr\": self.head_lr},\n",
    "                      {\"params\": adapter, \"lr\": self.adapter_lr}]\n",
    "            self.optimizer = torch.optim.AdamW(groups)\n",
    "        return self.optimizer\n",
    "\n",
    "# ---------------------------  helpers  --------------------------- #\n",
    "# def prepare_sst2_dataset(tokenizer, max_len=128):\n",
    "#     ds = load_dataset(\"glue\", \"sst2\")\n",
    "#     ds = ds.map(\n",
    "#         lambda ex: tokenizer(ex[\"sentence\"],\n",
    "#                              truncation=True,\n",
    "#                              padding=\"max_length\",\n",
    "#                              max_length=max_len),\n",
    "#         batched=True)\n",
    "#     ds = ds.rename_column(\"label\", \"labels\")\n",
    "#     ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "#     return ds\n",
    "\n",
    "def prepare_cola_dataset(tokenizer, max_len=128):\n",
    "    ds = load_dataset(\"glue\", \"cola\")\n",
    "    ds = ds.map(\n",
    "        lambda ex: tokenizer(\n",
    "            ex[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_len,\n",
    "        ),\n",
    "        batched=True,\n",
    "    )\n",
    "    ds = ds.rename_column(\"label\", \"labels\")\n",
    "    ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_id, use_fast=True)\n",
    "\n",
    "base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_id, num_labels=2, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "uilinlora_cfg = UILinLoRAConfig(\n",
    "        target_modules=[\"query\", \"value\"],\n",
    "        rank=128,\n",
    "        uilinlora_alpha=1.0,\n",
    "        uilinlora_dropout=0.0,\n",
    "        fan_in_fan_out=False,\n",
    "        init_uilinlora_weights=True,\n",
    "        task_type=TaskType.SEQ_CLS)\n",
    "\n",
    "model = get_peft_model(base, uilinlora_cfg)\n",
    "model.classifier.requires_grad_(True)   # make head trainable\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e478e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_cola_dataset(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"uilinlora-roberta-base-cola\",\n",
    "    per_device_train_batch_size=64,\n",
    "    num_train_epochs=4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_matthews_correlation\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.06,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = UILinLoRATrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    # train_dataset=data[\"train\"].select(range(1000)),\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    head_lr=1e-3,\n",
    "    adapter_lr=4e-3,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# print(\"Best-epoch accuracy:\",\n",
    "#         trainer.evaluate()[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283056bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trainer.evaluate().keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd69eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = trainer.evaluate()\n",
    "# print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = trainer.predict(data[\"validation\"])\n",
    "# print(\"Predictions:\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guyb_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
