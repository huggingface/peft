{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b4cfd741795038",
   "metadata": {},
   "source": [
    "## Initialize PolyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c7a99-5208-4d22-ac15-bacebe1b52f9",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import PolyConfig, get_peft_model, TaskType, PeftModel, PeftConfig\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model_name_or_path = \"google/flan-t5-large\"\n",
    "\n",
    "batch_size = 16\n",
    "lr = 5e-5\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1d2c6-0d35-4254-b9fb-035a426d86ae",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d701a4-7a4f-4eae-84bd-9e3a02b7ffca",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "peft_config = PolyConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    poly_type=\"poly\",\n",
    "    r=8,        \t\t# rank of lora in poly\n",
    "    n_tasks=4,  \t\t# # of tasks\n",
    "    n_skills=2, \t\t# # of skills (loras)\n",
    "    n_splits=4, \t\t# # of heads\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa695c2d-cf9c-432c-ab74-7e89f816ba13",
   "metadata": {},
   "source": [
    "## Prepare datasets\n",
    "\n",
    "For this example, we selected four `SuperGLUE` benchmark datasets: `boolq`, `multirc`, `rte`, and `wic`, each with a training set of 1,000 examples and an evaluation set of 100 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b36e7eff50657c",
   "metadata": {
    "collapsed": false,
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boolq\n",
    "boolq_dataset = (\n",
    "    load_dataset(\"super_glue\", \"boolq\")\n",
    "    .map(\n",
    "        lambda x: {\n",
    "            \"input\": f\"task_boolq {x['passage']}\\nQuestion: {x['question']}\\nA. Yes\\nB. No\\nAnswer:\",\n",
    "            # 0 - False\n",
    "            # 1 - True\n",
    "            \"output\": [\"B\", \"A\"][int(x['label'])],\n",
    "            \"task_name\": \"boolq\",\n",
    "        }\n",
    "    )\n",
    "    .select_columns([\"input\", \"output\", \"task_name\"])\n",
    ")\n",
    "print(\"boolq example: \")\n",
    "print(boolq_dataset['train'][0])\n",
    "\n",
    "# multirc\n",
    "multirc_dataset = (\n",
    "    load_dataset(\"super_glue\", \"multirc\")\n",
    "    .map(\n",
    "        lambda x: {\n",
    "            \"input\": (\n",
    "                f\"task_multirc {x['paragraph']}\\nQuestion: {x['question']}\\nAnswer: {x['answer']}\\nIs it\"\n",
    "                 \" true?\\nA. Yes\\nB. No\\nAnswer:\"\n",
    "            ),\n",
    "            # 0 - False\n",
    "            # 1 - True\n",
    "            \"output\": [\"B\", \"A\"][int(x['label'])],\n",
    "            \"task_name\": \"multirc\",\n",
    "        }\n",
    "    )\n",
    "    .select_columns([\"input\", \"output\", \"task_name\"])\n",
    ")\n",
    "print(\"multirc example: \")\n",
    "print(multirc_dataset['train'][0])\n",
    "\n",
    "# rte\n",
    "rte_dataset = (\n",
    "    load_dataset(\"super_glue\", \"rte\")\n",
    "    .map(\n",
    "        lambda x: {\n",
    "            \"input\": (\n",
    "                f\"task_rte {x['premise']}\\n{x['hypothesis']}\\nIs the sentence below entailed by the\"\n",
    "                \" sentence above?\\nA. Yes\\nB. No\\nAnswer:\"\n",
    "            ),\n",
    "            # 0 - entailment\n",
    "            # 1 - not_entailment\n",
    "            \"output\": [\"A\", \"B\"][int(x['label'])],\n",
    "            \"task_name\": \"rte\",\n",
    "        }\n",
    "    )\n",
    "    .select_columns([\"input\", \"output\", \"task_name\"])\n",
    ")\n",
    "print(\"rte example: \")\n",
    "print(rte_dataset['train'][0])\n",
    "\n",
    "# wic\n",
    "wic_dataset = (\n",
    "    load_dataset(\"super_glue\", \"wic\")\n",
    "    .map(\n",
    "        lambda x: {\n",
    "            \"input\": (\n",
    "                f\"task_wic Sentence 1: {x['sentence1']}\\nSentence 2: {x['sentence2']}\\nAre '{x['word']}'\"\n",
    "                \" in the above two sentences the same?\\nA. Yes\\nB. No\\nAnswer:\"\n",
    "            ),\n",
    "            # 0 - False\n",
    "            # 1 - True\n",
    "            \"output\": [\"B\", \"A\"][int(x['label'])],\n",
    "            \"task_name\": \"wic\",\n",
    "        }\n",
    "    )\n",
    "    .select_columns([\"input\", \"output\", \"task_name\"])\n",
    ")\n",
    "print(\"wic example: \")\n",
    "print(wic_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca2225-aaee-47aa-957a-5f8ed3177cdb",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# define a task2id map\n",
    "TASK2ID = {\n",
    "    \"boolq\": 0,\n",
    "    \"multirc\": 1,\n",
    "    \"rte\": 2,\n",
    "    \"wic\": 3,\n",
    "}\n",
    "\n",
    "def tokenize(examples):\n",
    "    inputs = examples[\"input\"]\n",
    "    targets = examples[\"output\"]\n",
    "    features = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    features[\"labels\"] = labels\n",
    "    features[\"task_ids\"] = [TASK2ID[t] for t in examples[\"task_name\"]]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6c31c-73cd-4eed-931b-0cad5d7290fb",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_superglue_dataset(\n",
    "    split=\"train\",\n",
    "    n_samples=500,\n",
    "):\n",
    "    ds = concatenate_datasets(\n",
    "        [\n",
    "            boolq_dataset[split].shuffle().select(range(n_samples)),\n",
    "            multirc_dataset[split].shuffle().select(range(n_samples)),\n",
    "            rte_dataset[split].shuffle().select(range(n_samples)),\n",
    "            wic_dataset[split].shuffle().select(range(n_samples)),\n",
    "        ]\n",
    "    )\n",
    "    ds = ds.map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        remove_columns=[\"input\", \"output\", \"task_name\"],\n",
    "        load_from_cache_file=False,\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6351c72-5ee2-450a-806c-e04e7c66f1d8",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "superglue_train_dataset = get_superglue_dataset(split=\"train\", n_samples=1000)\n",
    "superglue_eval_dataset = get_superglue_dataset(split=\"test\", n_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550abf92-b8ea-424b-aba0-10d8da941297",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48135d6-0d83-4e8a-b1f0-c292663c84ec",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# training and evaluation\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    preds = [ [ i for i in seq if i != -100 ] for seq in preds ]\n",
    "    labels = [ [ i for i in seq if i != -100 ] for seq in labels ]\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred, true in zip(preds, labels):\n",
    "        if pred.strip() == true.strip():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    accuracy = correct / total\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    \"output\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    learning_rate=lr,\n",
    "    num_train_epochs=num_epochs,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=[],\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=superglue_train_dataset,\n",
    "    eval_dataset=superglue_eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdad1ae-ecf0-4df1-bf27-6474c48c16be",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# saving model\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "model.save_pretrained(peft_model_id, safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e539e3d-0944-4f81-bcd6-dec16c66eeea",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ckpt = f\"{peft_model_id}/adapter_model.bin\"\n",
    "!du -h $ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e37b18-d760-4af7-b1ab-40a6880eb92d",
   "metadata": {},
   "source": [
    "## Load and infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70490c8e-d301-4e4e-a5a3-de87b53f1942",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae512b-545d-470d-874d-969dba42055b",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "i = 200\n",
    "task_ids = torch.LongTensor([TASK2ID[\"rte\"]])\n",
    "inputs = tokenizer(rte_dataset[\"validation\"][\"input\"][i], return_tensors=\"pt\")\n",
    "print(rte_dataset[\"validation\"][\"input\"][i])\n",
    "print(rte_dataset[\"validation\"][\"output\"][i])\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], task_ids=task_ids, max_new_tokens=2)\n",
    "    print(outputs)\n",
    "    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffbaf4-6ff1-41bd-8665-c51c402a45bc",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
