{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CPT Training and Inference\n",
        "This notebook demonstrates the training and evaluation process of Context-Aware Prompt Tuning (CPT) using the Hugging Face Trainer.\n",
        "\n",
        "## Sections Overview:\n",
        "1. **Setup**: Import libraries and configure the environment.\n",
        "2. **Data Preparation**: Load and preprocess the dataset.\n",
        "3. **Model Training**: Configure and train the model.\n",
        "4. **Evaluation**: Test the model's performance and visualize results."
      ],
      "metadata": {
        "id": "R_byvXT9lpTU"
      },
      "id": "R_byvXT9lpTU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "11b07b07ac5e472b"
      },
      "id": "11b07b07ac5e472b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "O8DWZb8ZrGRU"
      },
      "id": "O8DWZb8ZrGRU"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install git+https://github.com/huggingface/peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6KZ5REDrFiM",
        "outputId": "bb63626f-7b15-472e-db2a-a49ddeb06e06"
      },
      "id": "d6KZ5REDrFiM",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting git+https://github.com/huggingface/peft\n",
            "  Cloning https://github.com/huggingface/peft to /tmp/pip-req-build-8lz0lxes\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-8lz0lxes\n",
            "  Resolved https://github.com/huggingface/peft to commit d9aa0898e4a184464fe012afbf9af7adf0cf70d8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (0.4.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.13.3.dev0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.13.3.dev0) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.13.3.dev0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.25.0->peft==0.13.3.dev0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.13.3.dev0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.13.3.dev0) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.13.3.dev0) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.13.3.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.13.3.dev0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.13.3.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.13.3.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.13.3.dev0) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "5BerCvfkq_jp"
      },
      "id": "5BerCvfkq_jp"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "from peft import CPTConfig, get_peft_model\n",
        "from torch.utils.data import Dataset\n",
        "from typing import List, Union, Any, Dict, Mapping\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from tqdm import tqdm\n",
        "\n",
        "MAX_INPUT_LENGTH = 1024\n",
        "tokenizer_name_or_path = 'bigscience/bloom-1b7'"
      ],
      "metadata": {
        "id": "Y0pETNFBl963"
      },
      "id": "Y0pETNFBl963",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "---"
      ],
      "metadata": {
        "id": "9hO_I3aDmCQu"
      },
      "id": "9hO_I3aDmCQu"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    tokenizer_name_or_path, # The name or path of the pre-trained tokenizer (e.g., \"bert-base-uncased\").\n",
        "    cache_dir='.',          # Directory to cache the tokenizer files locally.\n",
        "    padding_side='right',   # Specifies that padding should be added to the right side of sequences.\n",
        "    trust_remote_code=True  # Allows loading tokenizer implementations from external sources.\n",
        ")"
      ],
      "metadata": {
        "id": "STK5N0LJrZmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e278f28-07ea-402a-9763-e45d856f1533"
      },
      "id": "STK5N0LJrZmA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SST-2 dataset from the GLUE benchmark\n",
        "dataset = load_dataset('glue', 'sst2')\n",
        "\n",
        "def add_string_labels(example):\n",
        "    \"\"\"\n",
        "    Converts numerical labels into human-readable string labels.\n",
        "\n",
        "    Args:\n",
        "        example (dict): A single example from the dataset with a numerical 'label'.\n",
        "\n",
        "    Returns:\n",
        "        dict: The example augmented with a 'label_text' field.\n",
        "    \"\"\"\n",
        "    # Map numerical label to string label\n",
        "    example['label_text'] = \"positive\" if example['label'] == 1 else \"negative\"\n",
        "    return example\n",
        "\n",
        "# Subset and process the training dataset\n",
        "train_dataset = dataset['train'].select(range(4)).map(add_string_labels)\n",
        "\n",
        "# Subset and process the validation dataset\n",
        "test_dataset = dataset['validation'].select(range(20)).map(add_string_labels)\n"
      ],
      "metadata": {
        "id": "C3oq4lDDrcUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "3f43ec3f88c44bd99e336a0df1bf841a",
            "57d68bc165094123ad69bf5e9f2b22e0",
            "6da7577b2d004176b0dc4dce017c19e6",
            "9d9353ac06e94f0fbc8cade13cd21112",
            "5e6aafbeb2dc42faa27faa91c80ed12f",
            "c705a295d54f4b159640fb0e664e9dcc",
            "0017a328390f457d8a1fbc1fa375a3b3",
            "a8aad2f2dcf84246bfa5d04c68ab01b6",
            "4da84ad05a824b0bbed49942fc3341b5",
            "f6f72911b1f34057943c83db219ea70c",
            "f53f298c55da45679735ffe3034b25cd",
            "cee26350cb864b898e3bd8cd1566b92d",
            "ccde9a03e3f648a3b87dfc82ef8bb5ae",
            "ec9a50a40e614b5b9c17a71ba66afe8d",
            "b022b2c33ed64b37926b65f00d53c3e1",
            "353310db4e374efead74cd0d28508528",
            "9ec9e26abef24229a28cf0c8eda1ed83",
            "191e1c6cc95c49c383df793fb293a6b1",
            "ae956e03517f4c5a9f433a4c97162558",
            "0cfe0a35ebbd48399f1d5b023c45b2c9",
            "3ec75b6fd95c4c6b842b352f0575f1bf",
            "ff936de96cdc4c4a8ca40c6fbcd28448"
          ]
        },
        "outputId": "4ddbed2d-67b1-4ac0-ad3f-56bf77272050"
      },
      "id": "C3oq4lDDrcUf",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f43ec3f88c44bd99e336a0df1bf841a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cee26350cb864b898e3bd8cd1566b92d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CPTDataset(Dataset):\n",
        "    def __init__(self, samples, tokenizer, template, max_length=MAX_INPUT_LENGTH):\n",
        "        \"\"\"\n",
        "        Initialize the CPTDataset with samples, a tokenizer, and a template.\n",
        "\n",
        "        Args:\n",
        "            samples (list): List of samples containing input sentences and labels.\n",
        "            tokenizer: Tokenizer instance for encoding text.\n",
        "            template (dict): Dictionary defining input/output templates and separators.\n",
        "            max_length (int): Maximum input length for truncation.\n",
        "        \"\"\"\n",
        "        self.template = template\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Storage for tokenized inputs and masks\n",
        "        self.attention_mask = []\n",
        "        self.input_ids = []\n",
        "        self.input_type_mask = []\n",
        "        self.inter_seperator_ids = self._get_input_ids(template['inter_seperator'])\n",
        "\n",
        "        # Tokenize each sample and prepare inputs\n",
        "        for sample_i in tqdm(samples):\n",
        "            input_text, label = sample_i['sentence'], sample_i['label_text']\n",
        "            input_ids, attention_mask, input_type_mask = self.preprocess_sentence(input_text, label)\n",
        "\n",
        "            self.input_ids.append(input_ids)\n",
        "            self.attention_mask.append(attention_mask)\n",
        "            self.input_type_mask.append(input_type_mask)\n",
        "\n",
        "\n",
        "    def _get_input_ids(self, text):\n",
        "        \"\"\"\n",
        "        Tokenize the given text into input IDs.\n",
        "\n",
        "        Args:\n",
        "            text (str): The text to tokenize.\n",
        "\n",
        "        Returns:\n",
        "            list: Tokenized input IDs.\n",
        "        \"\"\"\n",
        "        return self.tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "\n",
        "    def preprocess_sentence(self, input_text, label):\n",
        "        \"\"\"\n",
        "        Preprocess a sentence and its corresponding label using templates.\n",
        "\n",
        "        Args:\n",
        "            input_text (str): The input sentence.\n",
        "            label (str): The label text (e.g., \"positive\", \"negative\").\n",
        "\n",
        "        Returns:\n",
        "            tuple: (input_ids, attention_mask, input_type_mask)\n",
        "        \"\"\"\n",
        "\n",
        "        # Split input template into parts\n",
        "        input_template_part_1_text, input_template_part_2_text = self.template['input'].split('{}')\n",
        "        input_template_tokenized_part1 = self._get_input_ids(input_template_part_1_text)\n",
        "        input_tokenized = self._get_input_ids(input_text)\n",
        "        input_template_tokenized_part2 = self._get_input_ids(input_template_part_2_text)\n",
        "\n",
        "        # Separator token\n",
        "        sep_tokenized = self._get_input_ids(self.template['intra_seperator'])\n",
        "\n",
        "        # Process the label using the template\n",
        "        label_template_part_1, label_template_part_2 = self.template['output'].split('{}')\n",
        "        label_template_part1_tokenized = self._get_input_ids(label_template_part_1)\n",
        "        label_tokenized = self._get_input_ids(label)\n",
        "        label_template_part2_tokenized = self._get_input_ids(label_template_part_2)\n",
        "\n",
        "        # End-of-sequence token\n",
        "        eos = [self.tokenizer.eos_token_id] if self.tokenizer.eos_token_id is not None else []\n",
        "\n",
        "        # Concatenate all tokenized parts\n",
        "        input_ids = input_template_tokenized_part1 + input_tokenized + input_template_tokenized_part2 + sep_tokenized + label_template_part1_tokenized + label_tokenized + label_template_part2_tokenized + eos\n",
        "\n",
        "        # Generate attention and type masks\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        input_type_mask = [1] * len(input_template_tokenized_part1) + [2] * len(input_tokenized) + [1] * len(\n",
        "            input_template_tokenized_part2) + [0] * len(sep_tokenized) + \\\n",
        "                          [3] * len(label_template_part1_tokenized) + [4] * len(label_tokenized) + [3] * len( \\\n",
        "            label_template_part2_tokenized) + [0] * len(eos)\n",
        "\n",
        "        # Ensure all masks and inputs are the same length\n",
        "        assert len(input_type_mask) == len(input_ids) == len(attention_mask)\n",
        "\n",
        "        return input_ids, attention_mask, input_type_mask\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the number of examples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of examples.\n",
        "        \"\"\"\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get the tokenized representation for the given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the example.\n",
        "\n",
        "        Returns:\n",
        "            dict: Tokenized inputs with attention and type masks.\n",
        "        \"\"\"\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_mask[idx],\n",
        "            \"input_type_mask\": self.input_type_mask[idx]\n",
        "        }\n",
        "\n",
        "# Define templates for tokenization\n",
        "templates = {\n",
        "    'input': 'input: {}',     # Input template with placeholder\n",
        "    'intra_seperator': ' ',   # Separator between input and output\n",
        "    'output': 'output: {}',   # Output template with placeholder\n",
        "    'inter_seperator': '\\n'   # Separator between examples\n",
        "}\n",
        "\n",
        "# Initialize the dataset\n",
        "CPT_train_dataset = CPTDataset(train_dataset, tokenizer, templates)\n",
        "\n",
        "\n",
        "# - `templates`: Define how inputs and outputs should be formatted and separated.\n",
        "# - `CPTDataset`: Converts the raw dataset into tokenized input IDs and masks.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icJb6-Uqrf8p",
        "outputId": "0bd45083-9ea2-4d0f-e507-aee45fc93635"
      },
      "id": "icJb6-Uqrf8p",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 729.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Initialize storage for context-level information\n",
        "context_ids = []                # Concatenated input IDs for all samples\n",
        "context_attention_mask = []     # Concatenated attention masks\n",
        "context_input_type_mask = []    # Concatenated input type masks\n",
        "first_type_mask = 0             # Initial offset for input type mask\n",
        "\n",
        "# Iterate through the CPT training dataset\n",
        "for i in range(len(CPT_train_dataset)):\n",
        "    # Add input IDs to the context\n",
        "    context_ids += CPT_train_dataset[i]['input_ids']\n",
        "\n",
        "    # Add attention mask to the context\n",
        "    context_attention_mask += CPT_train_dataset[i]['attention_mask']\n",
        "\n",
        "    # Adjust and add the input type mask to the context\n",
        "    context_input_type_mask += [\n",
        "        i + first_type_mask if i > 0 else 0 # Increment type indices dynamically\n",
        "        for i in CPT_train_dataset[i]['input_type_mask']\n",
        "        ]\n",
        "\n",
        "    # Increment the type mask offset after processing the sample\n",
        "    first_type_mask += 4\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-22T09:24:58.894814Z",
          "start_time": "2024-10-22T09:24:58.893841Z"
        },
        "id": "aef03bbd5d86d3d8"
      },
      "id": "aef03bbd5d86d3d8",
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "\n",
        "---"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2c40f24774d83372"
      },
      "id": "2c40f24774d83372"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "p0jFTzkisMgN"
      },
      "id": "p0jFTzkisMgN"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Load a pre-trained causal language model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    'bigscience/bloom-1b7',\n",
        "    cache_dir='.',\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map='auto',\n",
        "    trust_remote_code=True,\n",
        "    local_files_only=False,\n",
        ")\n",
        "\n",
        "# Initialize the CPT configuration\n",
        "config = CPTConfig(\n",
        "            cpt_token_ids=context_ids,\n",
        "            cpt_mask=context_attention_mask,\n",
        "            cpt_tokens_type_mask=context_input_type_mask,\n",
        "\n",
        "            opt_weighted_loss_type='decay',\n",
        "            opt_loss_decay_factor=0.95,         # we choose the exponential decay factor applied to the loss\n",
        "            opt_projection_epsilon=0.2,         # we choose the projection over the input tokens\n",
        "            opt_projection_format_epsilon=0.1,  # we choose the projection over input and output templates\n",
        "\n",
        "            tokenizer_name_or_path=tokenizer_name_or_path,\n",
        ")\n",
        "\n",
        "# Initialize the CPT model with PEFT\n",
        "model = get_peft_model(base_model, config)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-22T09:25:08.941945Z",
          "start_time": "2024-10-22T09:25:04.393323Z"
        },
        "id": "17ac445134919a39"
      },
      "id": "17ac445134919a39",
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Collate Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4e49660c50d98741"
      },
      "id": "4e49660c50d98741"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class CPTDataCollatorForLanguageModeling(DataCollatorForLanguageModeling):\n",
        "    def __init__(self, tokenizer, training=True, mlm=False):\n",
        "        \"\"\"\n",
        "        Custom collator for CPT-style language modeling.\n",
        "\n",
        "        Args:\n",
        "            tokenizer: The tokenizer to handle tokenization and special tokens.\n",
        "            training (bool): If True, operates in training mode; otherwise in evaluation mode.\n",
        "            mlm (bool): If True, enables masked language modeling.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(tokenizer, mlm=mlm) # Initialize the parent class\n",
        "        self.training = training\n",
        "\n",
        "        # Add a special padding token if not already defined\n",
        "        self.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Process a batch of examples for language modeling.\n",
        "\n",
        "        Args:\n",
        "            examples (List): A batch of examples with tokenized inputs and optional sample masks.\n",
        "\n",
        "        Returns:\n",
        "            Dict: A dictionary containing padded and tensor-converted inputs, attention masks,\n",
        "                  input type masks, and optional sample masks and labels.\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize a list to collect sample masks if provided\n",
        "        list_sample_mask = []\n",
        "        for i in range(len(examples)):\n",
        "            if \"sample_mask\" in examples[i].keys():\n",
        "                list_sample_mask.append(examples[i].pop(\"sample_mask\"))\n",
        "\n",
        "        # Define a helper function for padding sequences to the maximum length\n",
        "        max_len = max(len(ex[\"input_ids\"]) for ex in examples)\n",
        "\n",
        "        # Define a helper function for padding sequences to the maximum length\n",
        "        def pad_sequence(sequence, max_len, pad_value=0):\n",
        "            return sequence + [pad_value] * (max_len - len(sequence))\n",
        "\n",
        "        # Pad and convert `input_ids`, `attention_mask`, and `input_type_mask` to tensors\n",
        "        input_ids = torch.tensor([pad_sequence(ex[\"input_ids\"], max_len) for ex in examples])\n",
        "        attention_mask = torch.tensor([pad_sequence(ex[\"attention_mask\"], max_len) for ex in examples])\n",
        "        input_type_mask = torch.tensor([pad_sequence(ex[\"input_type_mask\"], max_len) for ex in examples])\n",
        "\n",
        "        # Create the initial batch dictionary\n",
        "        batch = {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"input_type_mask\": input_type_mask}\n",
        "\n",
        "        # Create a tensor to store sample masks\n",
        "        tensor_sample_mask = batch[\"input_ids\"].clone().long()\n",
        "        tensor_sample_mask[:, :] = 0 # Initialize with zeros\n",
        "\n",
        "        # Populate the tensor with the provided sample masks\n",
        "        for i in range(len(list_sample_mask)):\n",
        "            tensor_sample_mask[i, : len(list_sample_mask[i])] = list_sample_mask[i]\n",
        "\n",
        "        # Copy `input_ids` to use as `labels`\n",
        "        batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
        "\n",
        "        # If in evaluation mode, include the `sample_mask` in the batch\n",
        "        if not self.training:\n",
        "            batch[\"sample_mask\"] = tensor_sample_mask\n",
        "\n",
        "        return batch\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-22T09:25:08.953199Z",
          "start_time": "2024-10-22T09:25:08.945689Z"
        },
        "id": "b0fac840f060e3aa"
      },
      "id": "b0fac840f060e3aa",
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "collapsed": false,
        "id": "48f535d74e6602b"
      },
      "id": "48f535d74e6602b"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:16, Epoch 25/25]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.392000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.316100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.577500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.985800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.640400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.420200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.194900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.886300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.861400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.669100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.588100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.483900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.509100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.320200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.355300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.184100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.091000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.963800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.875100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.919000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.757000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.675900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.612200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.675400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.623800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.465000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.447800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.393400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.378200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.326100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.293400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.370200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.344300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.226000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.200100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.206400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.167700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.171100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.130100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.189800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.093400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.108200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.131600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.082100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.097200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.050900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.045200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.016900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.024500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.012900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.022900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.008300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.015900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.009100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.6107212576223537, metrics={'train_runtime': 17.0713, 'train_samples_per_second': 5.858, 'train_steps_per_second': 5.858, 'total_flos': 14503280640000.0, 'train_loss': 0.6107212576223537, 'epoch': 25.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='../.',\n",
        "    use_cpu=False,\n",
        "    auto_find_batch_size=False,\n",
        "    learning_rate=1e-4,\n",
        "    logging_steps=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    save_total_limit=1,\n",
        "    remove_unused_columns=False,\n",
        "    num_train_epochs=25,\n",
        "    fp16=True,\n",
        "    save_strategy='no',\n",
        "    logging_dir=\"logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=CPT_train_dataset,  # Custom CPT training dataset.\n",
        "    data_collator=CPTDataCollatorForLanguageModeling(tokenizer, training=True, mlm=False)\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-22T09:25:27.599132Z",
          "start_time": "2024-10-22T09:25:13.906685Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1a865c2ad2dc7218",
        "outputId": "4798d0eb-9d7e-4aa2-eec6-ec1e3356aa65"
      },
      "id": "1a865c2ad2dc7218",
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "---"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b799ea89a567590f"
      },
      "id": "b799ea89a567590f"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1205.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: input: it 's a charming and often affecting journey .  output: positive</s> \n",
            " \t The prediction is: positive\n",
            " \t The GT is positive\n",
            "Sentence: input: unflinchingly bleak and desperate  output: negative</s> \n",
            " \t The prediction is: negative\n",
            " \t The GT is negative\n",
            "Sentence: input: allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker .  output: positive</s> \n",
            " \t The prediction is: positive\n",
            " \t The GT is positive\n",
            "Sentence: input: the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .  output: positive</s> \n",
            " \t The prediction is: positive\n",
            " \t The GT is positive\n",
            "Sentence: input: it 's slow -- very , very slow .  output: negative</s> \n",
            " \t The prediction is: negative\n",
            " \t The GT is negative\n",
            "Sentence: input: although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .  output: positive</s> \n",
            " \t The prediction is: negative\n",
            " \t The GT is positive\n",
            "Sentence: input: a sometimes tedious film .  output: negative</s> \n",
            " \t The prediction is: negative\n",
            " \t The GT is negative\n",
            "Sentence: input: or doing last year 's taxes with your ex-wife .  output: negative</s> \n",
            " \t The prediction is: negative\n",
            " \t The GT is negative\n",
            "Sentence: input: you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance .  output: positive</s> \n",
            " \t The prediction is: positive\n",
            " \t The GT is positive\n",
            "Sentence: input: in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey .  output: negative</s> \n",
            " \t The prediction is: negative\n",
            " \t The GT is negative\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "# Select relevant columns from the test dataset\n",
        "test_dataset = test_dataset.select_columns(['sentence', 'label_text'])\n",
        "\n",
        "# Convert the test dataset to a CPT-compatible format\n",
        "CPT_test_dataset = CPTDataset(test_dataset, tokenizer, templates)\n",
        "\n",
        "# Get the device where the model is loaded (CPU or GPU)\n",
        "device = model.device\n",
        "\n",
        "for i in range(10): # Evaluate the first 10 samples\n",
        "    input_ids, input_type_mask = CPT_test_dataset[i]['input_ids'], CPT_test_dataset[i]['input_type_mask']\n",
        "\n",
        "    # Pass the inputs through the model\n",
        "    outputs = model(\n",
        "        input_ids=torch.Tensor(input_ids).long().to(device=device).view(1, -1),\n",
        "        labels=torch.Tensor(input_ids).long().to(device=device).view(1, -1),\n",
        "        input_type_mask=torch.Tensor(input_type_mask).long().to(device=device).view(1, -1)\n",
        "    )\n",
        "\n",
        "    # Shift logits to exclude the last token and match the labels\n",
        "    shifted_logits = outputs.logits[..., :-1, :].contiguous().to(model.dtype)[0, -len(input_ids) + 1:]\n",
        "    shift_labels = torch.Tensor(input_ids).long().to(device=device).view(1, -1)[0, 1:].contiguous().to(device)\n",
        "    shifted_input_type_mask = torch.Tensor(input_type_mask).long().to(device=device).view(1, -1)[..., 1:].contiguous().to(device)\n",
        "\n",
        "    # Create a mask for the type `4` tokens (label tokens)\n",
        "    mask = torch.Tensor(shifted_input_type_mask).long().to(device=device).view(-1,) == 4\n",
        "\n",
        "    # Extract logits and labels corresponding to the mask\n",
        "    logit = shifted_logits[mask]\n",
        "    label = shift_labels[mask]\n",
        "\n",
        "    # All possible label tokens for `negative` and `positive`\n",
        "    all_labels = torch.Tensor([tokenizer(i, add_special_tokens=False)[\"input_ids\"] for i in ['negative', 'positive']]).long().to(device).view(-1,)\n",
        "\n",
        "    # Compare logits with label tokens and infer prediction\n",
        "    prediction = logit[0, torch.Tensor([tokenizer(i, add_special_tokens=False)[\"input_ids\"] for i in ['negative', 'positive']]).long().to(device).view(-1,)].argmax()\n",
        "    prediction_text = 'negative' if prediction == 0 else 'positive'\n",
        "    print('Sentence: {} \\n \\t The prediction is: {}\\n \\t The GT is {}'.format(\n",
        "        tokenizer.decode(input_ids),  # Decodes token IDs back to text\n",
        "        prediction_text,              # Model's predicted sentiment\n",
        "        tokenizer.decode(label)       # Ground truth sentiment label\n",
        "        ))\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-22T09:25:28.252009Z",
          "start_time": "2024-10-22T09:25:27.598326Z"
        },
        "id": "48e7d976e6e01212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35e7778-f0b5-419c-ab27-b4b865a47f53"
      },
      "id": "48e7d976e6e01212",
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "580805cb69ebec26"
      },
      "id": "580805cb69ebec26",
      "execution_count": 10
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "O8DWZb8ZrGRU",
        "5BerCvfkq_jp"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f43ec3f88c44bd99e336a0df1bf841a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57d68bc165094123ad69bf5e9f2b22e0",
              "IPY_MODEL_6da7577b2d004176b0dc4dce017c19e6",
              "IPY_MODEL_9d9353ac06e94f0fbc8cade13cd21112"
            ],
            "layout": "IPY_MODEL_5e6aafbeb2dc42faa27faa91c80ed12f"
          }
        },
        "57d68bc165094123ad69bf5e9f2b22e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c705a295d54f4b159640fb0e664e9dcc",
            "placeholder": "​",
            "style": "IPY_MODEL_0017a328390f457d8a1fbc1fa375a3b3",
            "value": "Map: 100%"
          }
        },
        "6da7577b2d004176b0dc4dce017c19e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8aad2f2dcf84246bfa5d04c68ab01b6",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da84ad05a824b0bbed49942fc3341b5",
            "value": 4
          }
        },
        "9d9353ac06e94f0fbc8cade13cd21112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6f72911b1f34057943c83db219ea70c",
            "placeholder": "​",
            "style": "IPY_MODEL_f53f298c55da45679735ffe3034b25cd",
            "value": " 4/4 [00:00&lt;00:00, 37.55 examples/s]"
          }
        },
        "5e6aafbeb2dc42faa27faa91c80ed12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c705a295d54f4b159640fb0e664e9dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0017a328390f457d8a1fbc1fa375a3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8aad2f2dcf84246bfa5d04c68ab01b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da84ad05a824b0bbed49942fc3341b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6f72911b1f34057943c83db219ea70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53f298c55da45679735ffe3034b25cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee26350cb864b898e3bd8cd1566b92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccde9a03e3f648a3b87dfc82ef8bb5ae",
              "IPY_MODEL_ec9a50a40e614b5b9c17a71ba66afe8d",
              "IPY_MODEL_b022b2c33ed64b37926b65f00d53c3e1"
            ],
            "layout": "IPY_MODEL_353310db4e374efead74cd0d28508528"
          }
        },
        "ccde9a03e3f648a3b87dfc82ef8bb5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ec9e26abef24229a28cf0c8eda1ed83",
            "placeholder": "​",
            "style": "IPY_MODEL_191e1c6cc95c49c383df793fb293a6b1",
            "value": "Map: 100%"
          }
        },
        "ec9a50a40e614b5b9c17a71ba66afe8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae956e03517f4c5a9f433a4c97162558",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cfe0a35ebbd48399f1d5b023c45b2c9",
            "value": 20
          }
        },
        "b022b2c33ed64b37926b65f00d53c3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec75b6fd95c4c6b842b352f0575f1bf",
            "placeholder": "​",
            "style": "IPY_MODEL_ff936de96cdc4c4a8ca40c6fbcd28448",
            "value": " 20/20 [00:00&lt;00:00, 160.00 examples/s]"
          }
        },
        "353310db4e374efead74cd0d28508528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec9e26abef24229a28cf0c8eda1ed83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191e1c6cc95c49c383df793fb293a6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae956e03517f4c5a9f433a4c97162558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfe0a35ebbd48399f1d5b023c45b2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ec75b6fd95c4c6b842b352f0575f1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff936de96cdc4c4a8ca40c6fbcd28448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}