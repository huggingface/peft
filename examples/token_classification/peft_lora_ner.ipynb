{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer, pipeline\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"conll2003\")\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the tokens of the first training example\n",
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the NER tags of the first training example\n",
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the label names for the NER tags\n",
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to boycott British lamb . \n",
      "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\open_source\\peft-folder\\ner-examples\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the first training example\n",
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
      "[-100, 1, 2, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mappings\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 108,021,513 || trainable%: 0.2730\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA (Low-Rank Adaptation) for fine-tuning\n",
    "peft_config = LoraConfig(target_modules = [\"query\", \"key\"])\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4b44fe9b34e9bb60de391325f2e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\open_source\\peft-folder\\ner-examples\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner-lora\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    label_names=[\"labels\"],\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2dabf65ba646efa5b166e087ae4617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\open_source\\peft-folder\\ner-examples\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.078, 'grad_norm': 0.1591925472021103, 'learning_rate': 1.9715261958997724e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7335, 'grad_norm': 0.35751551389694214, 'learning_rate': 1.9430523917995446e-05, 'epoch': 0.57}\n",
      "{'loss': 1.23, 'grad_norm': 0.3602656126022339, 'learning_rate': 1.9145785876993168e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9996064910294253b144ff5c2ea46b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\open_source\\peft-folder\\ner-examples\\.venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9907475709915161, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.7612733266615648, 'eval_runtime': 5.9505, 'eval_samples_per_second': 546.17, 'eval_steps_per_second': 68.397, 'epoch': 1.0}\n",
      "{'loss': 1.0322, 'grad_norm': 0.3555365800857544, 'learning_rate': 1.886104783599089e-05, 'epoch': 1.14}\n",
      "{'loss': 0.9505, 'grad_norm': 0.41112151741981506, 'learning_rate': 1.8576309794988612e-05, 'epoch': 1.42}\n",
      "{'loss': 0.8768, 'grad_norm': 0.5796128511428833, 'learning_rate': 1.8291571753986334e-05, 'epoch': 1.71}\n",
      "{'loss': 0.8245, 'grad_norm': 0.974592387676239, 'learning_rate': 1.8006833712984056e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e43d2706c64a89b959dafcecee6089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7515557408332825, 'eval_precision': 0.03552158273381295, 'eval_recall': 0.013295186805789297, 'eval_f1': 0.01934851824638746, 'eval_accuracy': 0.7825984576440808, 'eval_runtime': 6.0164, 'eval_samples_per_second': 540.189, 'eval_steps_per_second': 67.648, 'epoch': 2.0}\n",
      "{'loss': 0.7702, 'grad_norm': 0.42826271057128906, 'learning_rate': 1.7722095671981778e-05, 'epoch': 2.28}\n",
      "{'loss': 0.7507, 'grad_norm': 0.37430691719055176, 'learning_rate': 1.74373576309795e-05, 'epoch': 2.56}\n",
      "{'loss': 0.7328, 'grad_norm': 0.5020062327384949, 'learning_rate': 1.7152619589977222e-05, 'epoch': 2.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba21a360b6364f26bb8ba58381de59e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6854819059371948, 'eval_precision': 0.2120204036371701, 'eval_recall': 0.16088858970043757, 'eval_f1': 0.18294900009568466, 'eval_accuracy': 0.8159033378465885, 'eval_runtime': 6.0089, 'eval_samples_per_second': 540.863, 'eval_steps_per_second': 67.733, 'epoch': 3.0}\n",
      "{'loss': 0.7137, 'grad_norm': 0.45179906487464905, 'learning_rate': 1.6867881548974945e-05, 'epoch': 3.13}\n",
      "{'loss': 0.7161, 'grad_norm': 0.46217212080955505, 'learning_rate': 1.6583143507972667e-05, 'epoch': 3.42}\n",
      "{'loss': 0.6882, 'grad_norm': 0.31135469675064087, 'learning_rate': 1.629840546697039e-05, 'epoch': 3.7}\n",
      "{'loss': 0.6738, 'grad_norm': 0.3984847366809845, 'learning_rate': 1.601366742596811e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019de4a242a745dea78e090d499489a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6545637249946594, 'eval_precision': 0.2585321100917431, 'eval_recall': 0.23712554695388757, 'eval_f1': 0.24736657303370782, 'eval_accuracy': 0.8250721139695061, 'eval_runtime': 6.19, 'eval_samples_per_second': 525.041, 'eval_steps_per_second': 65.751, 'epoch': 4.0}\n",
      "{'loss': 0.6759, 'grad_norm': 0.2769240438938141, 'learning_rate': 1.5728929384965833e-05, 'epoch': 4.27}\n",
      "{'loss': 0.6697, 'grad_norm': 0.24548429250717163, 'learning_rate': 1.5444191343963555e-05, 'epoch': 4.56}\n",
      "{'loss': 0.6639, 'grad_norm': 0.382127046585083, 'learning_rate': 1.5159453302961277e-05, 'epoch': 4.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7f550fcecd471689543dd4514b3f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.633837878704071, 'eval_precision': 0.2685346327880265, 'eval_recall': 0.25967687647256815, 'eval_f1': 0.264031485284052, 'eval_accuracy': 0.828074409842821, 'eval_runtime': 6.2211, 'eval_samples_per_second': 522.417, 'eval_steps_per_second': 65.423, 'epoch': 5.0}\n",
      "{'loss': 0.6516, 'grad_norm': 0.4856937527656555, 'learning_rate': 1.4874715261958999e-05, 'epoch': 5.13}\n",
      "{'loss': 0.6443, 'grad_norm': 0.25792446732521057, 'learning_rate': 1.4589977220956721e-05, 'epoch': 5.41}\n",
      "{'loss': 0.6406, 'grad_norm': 0.2429998368024826, 'learning_rate': 1.4305239179954442e-05, 'epoch': 5.69}\n",
      "{'loss': 0.6447, 'grad_norm': 0.3957258462905884, 'learning_rate': 1.4020501138952165e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930edf14b2374bc18a3ef5daf5e85fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6184056401252747, 'eval_precision': 0.27051567586088743, 'eval_recall': 0.2657354426119152, 'eval_f1': 0.26810425333220134, 'eval_accuracy': 0.8326808736092306, 'eval_runtime': 6.0353, 'eval_samples_per_second': 538.495, 'eval_steps_per_second': 67.436, 'epoch': 6.0}\n",
      "{'loss': 0.6377, 'grad_norm': 0.5821410417556763, 'learning_rate': 1.3735763097949887e-05, 'epoch': 6.26}\n",
      "{'loss': 0.6451, 'grad_norm': 0.3864973187446594, 'learning_rate': 1.3451025056947608e-05, 'epoch': 6.55}\n",
      "{'loss': 0.6218, 'grad_norm': 0.288789302110672, 'learning_rate': 1.3166287015945332e-05, 'epoch': 6.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a78a7bae1f449c9b8fa5126e19ede1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6061442494392395, 'eval_precision': 0.28368673050615595, 'eval_recall': 0.2791989229215752, 'eval_f1': 0.28142493638676847, 'eval_accuracy': 0.8382439512568435, 'eval_runtime': 6.1302, 'eval_samples_per_second': 530.164, 'eval_steps_per_second': 66.393, 'epoch': 7.0}\n",
      "{'loss': 0.6377, 'grad_norm': 0.31197211146354675, 'learning_rate': 1.2881548974943054e-05, 'epoch': 7.12}\n",
      "{'loss': 0.6224, 'grad_norm': 0.2910526990890503, 'learning_rate': 1.2596810933940776e-05, 'epoch': 7.4}\n",
      "{'loss': 0.6199, 'grad_norm': 0.6478071808815002, 'learning_rate': 1.2312072892938498e-05, 'epoch': 7.69}\n",
      "{'loss': 0.6095, 'grad_norm': 0.34126749634742737, 'learning_rate': 1.2027334851936218e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183ba353646342b8b519be5a3f94dc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5944703817367554, 'eval_precision': 0.30005000833472245, 'eval_recall': 0.30292830696735107, 'eval_f1': 0.3014822879155849, 'eval_accuracy': 0.8419968210984871, 'eval_runtime': 6.0547, 'eval_samples_per_second': 536.772, 'eval_steps_per_second': 67.22, 'epoch': 8.0}\n",
      "{'loss': 0.6007, 'grad_norm': 0.3512535095214844, 'learning_rate': 1.1742596810933942e-05, 'epoch': 8.26}\n",
      "{'loss': 0.6189, 'grad_norm': 0.5323229432106018, 'learning_rate': 1.1457858769931664e-05, 'epoch': 8.54}\n",
      "{'loss': 0.6066, 'grad_norm': 0.22804991900920868, 'learning_rate': 1.1173120728929384e-05, 'epoch': 8.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ed4712dd2b4c28abe231f74a4e84ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.582589328289032, 'eval_precision': 0.3131099544567339, 'eval_recall': 0.3239649949511949, 'eval_f1': 0.3184449958643507, 'eval_accuracy': 0.8446459056925885, 'eval_runtime': 6.0909, 'eval_samples_per_second': 533.582, 'eval_steps_per_second': 66.821, 'epoch': 9.0}\n",
      "{'loss': 0.6082, 'grad_norm': 1.0766414403915405, 'learning_rate': 1.0888382687927108e-05, 'epoch': 9.11}\n",
      "{'loss': 0.6021, 'grad_norm': 0.4065483510494232, 'learning_rate': 1.060364464692483e-05, 'epoch': 9.4}\n",
      "{'loss': 0.5961, 'grad_norm': 0.5232006311416626, 'learning_rate': 1.0318906605922552e-05, 'epoch': 9.68}\n",
      "{'loss': 0.5934, 'grad_norm': 0.3136926591396332, 'learning_rate': 1.0034168564920275e-05, 'epoch': 9.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7da71d13774723b4d5fa6c8560a738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5725618004798889, 'eval_precision': 0.3304, 'eval_recall': 0.3475260854931, 'eval_f1': 0.338746719160105, 'eval_accuracy': 0.849693883558015, 'eval_runtime': 6.2953, 'eval_samples_per_second': 516.255, 'eval_steps_per_second': 64.651, 'epoch': 10.0}\n",
      "{'loss': 0.5814, 'grad_norm': 0.33662763237953186, 'learning_rate': 9.749430523917997e-06, 'epoch': 10.25}\n",
      "{'loss': 0.5991, 'grad_norm': 0.236420139670372, 'learning_rate': 9.464692482915719e-06, 'epoch': 10.54}\n",
      "{'loss': 0.5827, 'grad_norm': 0.4665989577770233, 'learning_rate': 9.17995444191344e-06, 'epoch': 10.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2ab9d455d84494bb1c5b02cd8bd3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.555459201335907, 'eval_precision': 0.349606766582579, 'eval_recall': 0.3964994951194884, 'eval_f1': 0.3715795284283574, 'eval_accuracy': 0.8574056631541768, 'eval_runtime': 6.2601, 'eval_samples_per_second': 519.162, 'eval_steps_per_second': 65.015, 'epoch': 11.0}\n",
      "{'loss': 0.5827, 'grad_norm': 0.4704764187335968, 'learning_rate': 8.895216400911163e-06, 'epoch': 11.1}\n",
      "{'loss': 0.5803, 'grad_norm': 0.4113923907279968, 'learning_rate': 8.610478359908885e-06, 'epoch': 11.39}\n",
      "{'loss': 0.5842, 'grad_norm': 0.29213693737983704, 'learning_rate': 8.325740318906607e-06, 'epoch': 11.67}\n",
      "{'loss': 0.5697, 'grad_norm': 0.2828220725059509, 'learning_rate': 8.041002277904329e-06, 'epoch': 11.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88672826854412197df60907c8b2152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5435853600502014, 'eval_precision': 0.38317217491701544, 'eval_recall': 0.4468192527768428, 'eval_f1': 0.4125553570041178, 'eval_accuracy': 0.8646759286513216, 'eval_runtime': 6.0454, 'eval_samples_per_second': 537.6, 'eval_steps_per_second': 67.324, 'epoch': 12.0}\n",
      "{'loss': 0.5642, 'grad_norm': 0.5388419032096863, 'learning_rate': 7.75626423690205e-06, 'epoch': 12.24}\n",
      "{'loss': 0.5771, 'grad_norm': 0.3611924350261688, 'learning_rate': 7.471526195899773e-06, 'epoch': 12.53}\n",
      "{'loss': 0.5689, 'grad_norm': 0.7496384382247925, 'learning_rate': 7.186788154897495e-06, 'epoch': 12.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c061540961f14f8f99b22086e0319aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5335272550582886, 'eval_precision': 0.3891377379619261, 'eval_recall': 0.46785594076068665, 'eval_f1': 0.42488155280452394, 'eval_accuracy': 0.8692235238711956, 'eval_runtime': 6.4315, 'eval_samples_per_second': 505.327, 'eval_steps_per_second': 63.283, 'epoch': 13.0}\n",
      "{'loss': 0.5669, 'grad_norm': 0.4726976454257965, 'learning_rate': 6.9020501138952166e-06, 'epoch': 13.1}\n",
      "{'loss': 0.5683, 'grad_norm': 0.49205562472343445, 'learning_rate': 6.617312072892939e-06, 'epoch': 13.38}\n",
      "{'loss': 0.5579, 'grad_norm': 0.4790692627429962, 'learning_rate': 6.3325740318906616e-06, 'epoch': 13.67}\n",
      "{'loss': 0.5601, 'grad_norm': 0.3624199628829956, 'learning_rate': 6.047835990888384e-06, 'epoch': 13.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856edda3345642efba80f2d623f80062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5271334648132324, 'eval_precision': 0.4016842105263158, 'eval_recall': 0.48165600807808817, 'eval_f1': 0.438050049743629, 'eval_accuracy': 0.8724612939306529, 'eval_runtime': 6.177, 'eval_samples_per_second': 526.148, 'eval_steps_per_second': 65.89, 'epoch': 14.0}\n",
      "{'loss': 0.5611, 'grad_norm': 0.33320072293281555, 'learning_rate': 5.763097949886105e-06, 'epoch': 14.24}\n",
      "{'loss': 0.5431, 'grad_norm': 0.5229126811027527, 'learning_rate': 5.478359908883827e-06, 'epoch': 14.52}\n",
      "{'loss': 0.5553, 'grad_norm': 0.5381569266319275, 'learning_rate': 5.19362186788155e-06, 'epoch': 14.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2b60c8edf9464181864a275e1d88d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5203945636749268, 'eval_precision': 0.40960491414211925, 'eval_recall': 0.4937731403567822, 'eval_f1': 0.4477680274704312, 'eval_accuracy': 0.8755960440336729, 'eval_runtime': 6.0302, 'eval_samples_per_second': 538.957, 'eval_steps_per_second': 67.494, 'epoch': 15.0}\n",
      "{'loss': 0.5664, 'grad_norm': 0.45702916383743286, 'learning_rate': 4.908883826879272e-06, 'epoch': 15.09}\n",
      "{'loss': 0.5511, 'grad_norm': 0.8291336894035339, 'learning_rate': 4.624145785876993e-06, 'epoch': 15.38}\n",
      "{'loss': 0.5535, 'grad_norm': 1.0453912019729614, 'learning_rate': 4.339407744874715e-06, 'epoch': 15.66}\n",
      "{'loss': 0.5474, 'grad_norm': 0.5797114372253418, 'learning_rate': 4.054669703872437e-06, 'epoch': 15.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902fca10a3d048b98c71b034ed10c232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5146547555923462, 'eval_precision': 0.4094542447629548, 'eval_recall': 0.5, 'eval_f1': 0.45021973026216094, 'eval_accuracy': 0.8776858774356862, 'eval_runtime': 5.9717, 'eval_samples_per_second': 544.235, 'eval_steps_per_second': 68.155, 'epoch': 16.0}\n",
      "{'loss': 0.556, 'grad_norm': 0.26725882291793823, 'learning_rate': 3.76993166287016e-06, 'epoch': 16.23}\n",
      "{'loss': 0.5464, 'grad_norm': 0.8311058878898621, 'learning_rate': 3.4851936218678815e-06, 'epoch': 16.51}\n",
      "{'loss': 0.546, 'grad_norm': 0.620249330997467, 'learning_rate': 3.200455580865604e-06, 'epoch': 16.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abbad18eb0c45a28a1702cee0256d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5108492970466614, 'eval_precision': 0.4133003572410003, 'eval_recall': 0.5062268596432178, 'eval_f1': 0.45506807866868376, 'eval_accuracy': 0.8792458939188792, 'eval_runtime': 6.0242, 'eval_samples_per_second': 539.491, 'eval_steps_per_second': 67.561, 'epoch': 17.0}\n",
      "{'loss': 0.551, 'grad_norm': 0.40934082865715027, 'learning_rate': 2.9157175398633257e-06, 'epoch': 17.08}\n",
      "{'loss': 0.548, 'grad_norm': 0.5092348456382751, 'learning_rate': 2.6309794988610482e-06, 'epoch': 17.37}\n",
      "{'loss': 0.5372, 'grad_norm': 0.352668821811676, 'learning_rate': 2.34624145785877e-06, 'epoch': 17.65}\n",
      "{'loss': 0.5434, 'grad_norm': 0.4402916729450226, 'learning_rate': 2.061503416856492e-06, 'epoch': 17.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5605b6f245c44a38ba996dccc2dd805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5081017017364502, 'eval_precision': 0.41836173721825176, 'eval_recall': 0.5122854257825648, 'eval_f1': 0.4605840520502345, 'eval_accuracy': 0.8803791134396892, 'eval_runtime': 6.003, 'eval_samples_per_second': 541.395, 'eval_steps_per_second': 67.799, 'epoch': 18.0}\n",
      "{'loss': 0.5611, 'grad_norm': 0.4256851077079773, 'learning_rate': 1.7767653758542143e-06, 'epoch': 18.22}\n",
      "{'loss': 0.5421, 'grad_norm': 0.4777807891368866, 'learning_rate': 1.4920273348519363e-06, 'epoch': 18.51}\n",
      "{'loss': 0.541, 'grad_norm': 0.8818345665931702, 'learning_rate': 1.2072892938496584e-06, 'epoch': 18.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e60034798964cd3ba445401fe8a20b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5060338973999023, 'eval_precision': 0.41805974239517674, 'eval_recall': 0.51346348030966, 'eval_f1': 0.4608761329305136, 'eval_accuracy': 0.8807470418555365, 'eval_runtime': 6.0613, 'eval_samples_per_second': 536.192, 'eval_steps_per_second': 67.148, 'epoch': 19.0}\n",
      "{'loss': 0.5448, 'grad_norm': 0.8677995800971985, 'learning_rate': 9.225512528473805e-07, 'epoch': 19.08}\n",
      "{'loss': 0.5457, 'grad_norm': 0.4022636115550995, 'learning_rate': 6.378132118451026e-07, 'epoch': 19.36}\n",
      "{'loss': 0.5469, 'grad_norm': 0.2670786380767822, 'learning_rate': 3.530751708428246e-07, 'epoch': 19.65}\n",
      "{'loss': 0.5438, 'grad_norm': 0.37346577644348145, 'learning_rate': 6.83371298405467e-08, 'epoch': 19.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2baada7153844793bf46308967432fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5054147839546204, 'eval_precision': 0.4196245032205016, 'eval_recall': 0.5153147088522383, 'eval_f1': 0.4625727018656998, 'eval_accuracy': 0.8810266674515806, 'eval_runtime': 5.9604, 'eval_samples_per_second': 545.267, 'eval_steps_per_second': 68.284, 'epoch': 20.0}\n",
      "{'train_runtime': 1317.1526, 'train_samples_per_second': 213.202, 'train_steps_per_second': 26.664, 'train_loss': 0.6646072788499211, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35120, training_loss=0.6646072788499211, metrics={'train_runtime': 1317.1526, 'train_samples_per_second': 213.202, 'train_steps_per_second': 26.664, 'total_flos': 6167088240555726.0, 'train_loss': 0.6646072788499211, 'epoch': 20.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9957055),\n",
       "  'word': 'Jino',\n",
       "  'start': 11,\n",
       "  'end': 15}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"bert-finetuned-ner-lora\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(\"My name is Jino.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
