{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef57047",
   "metadata": {},
   "source": [
    "# Using PEFT with timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80561acc",
   "metadata": {},
   "source": [
    "`peft` allows us to train any model with LoRA as long as the layer type is supported. Since `Conv2D` is one of the supported layer types, it makes sense to test it on image models.\n",
    "\n",
    "In this short notebook, we will demonstrate this with an image classification task using [`timm`](https://huggingface.co/docs/timm/index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26c285",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b9040",
   "metadata": {},
   "source": [
    "Make sure that you have the latest version of `peft` installed. To ensure that, run this in your Python environment:\n",
    "    \n",
    "    python -m pip install --upgrade peft\n",
    "    \n",
    "Also, ensure that `timm` is installed:\n",
    "\n",
    "    python -m pip install --upgrade timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peft\n",
    "from peft.utils import infer_device\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c628fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ab69c",
   "metadata": {},
   "source": [
    "## Loading the pre-trained base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bff51a",
   "metadata": {},
   "source": [
    "We use a small pretrained `timm` model, `PoolFormer`. Find more info on its [model card](https://huggingface.co/timm/poolformer_m36.sail_in1k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_timm = \"timm/poolformer_m36.sail_in1k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc06f9b",
   "metadata": {},
   "source": [
    "We tell `timm` that we deal with 3 classes, to ensure that the classification layer has the correct size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090564bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_id_timm, pretrained=True, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca5794",
   "metadata": {},
   "source": [
    "These are the transformations steps necessary to process the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f809dfa",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398fe22",
   "metadata": {},
   "source": [
    "For this exercise, we use the \"beans\" dataset. More details on the dataset can be found on [its datasets page](https://huggingface.co/datasets/beans). For our purposes, what's important is that we have image inputs and the target we're trying to predict is one of three classes for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fddc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"beans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds[\"train\"]\n",
    "ds_valid = ds[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ea6c4",
   "metadata": {},
   "source": [
    "We define a small processing function which is responsible for loading and transforming the images, as well as extracting the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142df842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(batch):\n",
    "    x = torch.cat([transform(img).unsqueeze(0) for img in batch[\"image\"]])\n",
    "    y = torch.tensor(batch[\"labels\"])\n",
    "    return {\"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.set_transform(process)\n",
    "ds_valid.set_transform(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282374be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ds_train, batch_size=32)\n",
    "valid_loader = torch.utils.data.DataLoader(ds_valid, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd3329",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969bc374",
   "metadata": {},
   "source": [
    "This is just a function that performs the train loop, nothing fancy happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, valid_dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            xb, yb = batch[\"x\"], batch[\"y\"]\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            lsm = torch.nn.functional.log_softmax(outputs, dim=-1)\n",
    "            loss = criterion(lsm, yb)\n",
    "            train_loss += loss.detach().float()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        n_total = 0\n",
    "        for batch in valid_dataloader:\n",
    "            xb, yb = batch[\"x\"], batch[\"y\"]\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(xb)\n",
    "            lsm = torch.nn.functional.log_softmax(outputs, dim=-1)\n",
    "            loss = criterion(lsm, yb)\n",
    "            valid_loss += loss.detach().float()\n",
    "            correct += (outputs.argmax(-1) == yb).sum().item()\n",
    "            n_total += len(yb)\n",
    "\n",
    "        train_loss_total = (train_loss / len(train_dataloader)).item()\n",
    "        valid_loss_total = (valid_loss / len(valid_dataloader)).item()\n",
    "        valid_acc_total = correct / n_total\n",
    "        print(f\"{epoch=:<2}  {train_loss_total=:.4f}  {valid_loss_total=:.4f}  {valid_acc_total=:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd58357",
   "metadata": {},
   "source": [
    "### Selecting which layers to fine-tune with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987321c",
   "metadata": {},
   "source": [
    "Let's take a look at the layers of our model. We only print the first 30, since there are quite a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(n, type(m)) for n, m in model.named_modules()][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af9349",
   "metadata": {},
   "source": [
    "Most of these layers are not good targets for LoRA, but we see a couple that should interest us. Their names are `'stages.0.blocks.0.mlp.fc1'`, etc. With a bit of regex, we can match them easily.\n",
    "\n",
    "Also, we should inspect the name of the classification layer, since we want to train that one too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(n, type(m)) for n, m in model.named_modules()][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e75b78",
   "metadata": {},
   "source": [
    "    config = peft.LoraConfig(\n",
    "        r=8,\n",
    "        target_modules=r\".*\\.mlp\\.fc\\d|head\\.fc\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23814d70",
   "metadata": {},
   "source": [
    "Okay, this gives us all the information we need to fine-tune this model. With a bit of regex, we match the convolutional layers that should be targeted for LoRA. We also want to train the classification layer `'head.fc'` (without LoRA), so we add it to the `modules_to_save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81029587",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(r=8, target_modules=r\".*\\.mlp\\.fc\\d\", modules_to_save=[\"head.fc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05876bc",
   "metadata": {},
   "source": [
    "Finally, let's create the `peft` model, the optimizer and criterion, and we can get started. As shown below, less than 2% of the model's total parameters are updated thanks to `peft`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = infer_device()\n",
    "peft_model = peft.get_peft_model(model, config).to(device)\n",
    "optimizer = torch.optim.Adam(peft_model.parameters(), lr=2e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e557e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train(peft_model, optimizer, criterion, train_loader, valid_dataloader=valid_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94162859",
   "metadata": {},
   "source": [
    "We get an accuracy of ~0.97, despite only training a tiny amount of parameters. That's a really nice result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16bad8",
   "metadata": {},
   "source": [
    "## Sharing the model through Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e16c7",
   "metadata": {},
   "source": [
    "### Pushing the model to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec596b3b",
   "metadata": {},
   "source": [
    "If we want to share the fine-tuned weights with the world, we can upload them to Hugging Face Hub like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"BenjaminB\"  # put your user name here\n",
    "model_name = \"peft-lora-with-timm-model\"\n",
    "model_id = f\"{user}/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.push_to_hub(model_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80155ca7",
   "metadata": {},
   "source": [
    "As we can see, the adapter size is only 4.3 MB. The original model was 225 MB. That's a very big saving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d831e60",
   "metadata": {},
   "source": [
    "### Loading the model from HF Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5c641",
   "metadata": {},
   "source": [
    "Now, it only takes one step to load the model from HF Hub. To do this, we can use `PeftModel.from_pretrained`, passing our base model and the model ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc69183",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = timm.create_model(model_id_timm, pretrained=True, num_classes=3)\n",
    "loaded = peft.PeftModel.from_pretrained(base_model, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19882a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds_train[:1][\"x\"]\n",
    "y_peft = peft_model(x.to(device))\n",
    "y_loaded = loaded(x)\n",
    "torch.allclose(y_peft.cpu(), y_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d2ab2",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc262bcd",
   "metadata": {},
   "source": [
    "Finally, as a clean up step, you may want to delete the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import delete_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_repo(model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
