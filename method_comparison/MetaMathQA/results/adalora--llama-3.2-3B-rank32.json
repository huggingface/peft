{
  "run_info": {
    "created_at": "2026-01-09T17:02:52+00:00",
    "total_time": 1339.9807203459786,
    "experiment_name": "adalora/llama-3.2-3B-rank32",
    "peft_branch": "main",
    "train_config": {
      "model_id": "meta-llama/Llama-3.2-3B",
      "dtype": "bfloat16",
      "max_seq_length": 768,
      "batch_size": 4,
      "batch_size_eval": 50,
      "max_steps": 5000,
      "eval_steps": 250,
      "compile": false,
      "query_template": "Question: {query} Think step by step.\nAnswer:",
      "seed": 0,
      "grad_norm_clip": 1.0,
      "optimizer_type": "AdamW",
      "optimizer_kwargs": {
        "lr": 0.0001,
        "weight_decay": 0.1
      },
      "lr_scheduler": "cosine",
      "use_amp": false,
      "autocast_adapter_dtype": true,
      "generation_kwargs": {
        "max_length": 800,
        "max_new_tokens": 300
      },
      "attn_implementation": null
    },
    "peft_config": {
      "task_type": null,
      "peft_type": "ADALORA",
      "auto_mapping": null,
      "peft_version": "0.18.1.dev0@UNKNOWN",
      "base_model_name_or_path": "meta-llama/Llama-3.2-3B",
      "revision": null,
      "inference_mode": false,
      "r": 8,
      "target_modules": [
        "q_proj",
        "v_proj"
      ],
      "exclude_modules": null,
      "lora_alpha": 8,
      "lora_dropout": 0.0,
      "fan_in_fan_out": false,
      "bias": "none",
      "use_rslora": false,
      "modules_to_save": null,
      "init_lora_weights": true,
      "layers_to_transform": null,
      "layers_pattern": null,
      "rank_pattern": {
        "model.layers.0.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.0.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.1.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false
        ],
        "model.layers.1.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.2.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false
        ],
        "model.layers.2.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true
        ],
        "model.layers.3.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.3.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true
        ],
        "model.layers.4.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false
        ],
        "model.layers.4.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.5.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.5.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true
        ],
        "model.layers.6.self_attn.q_proj.lora_E": [
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.6.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true
        ],
        "model.layers.7.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.7.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.8.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.8.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.9.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.9.self_attn.v_proj.lora_E": [
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.10.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.10.self_attn.v_proj.lora_E": [
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true
        ],
        "model.layers.11.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false
        ],
        "model.layers.11.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.12.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.12.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false
        ],
        "model.layers.13.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.13.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true
        ],
        "model.layers.14.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.14.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false
        ],
        "model.layers.15.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.15.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.16.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.16.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false
        ],
        "model.layers.17.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.17.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.18.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.18.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true
        ],
        "model.layers.19.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true
        ],
        "model.layers.19.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.20.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.20.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true
        ],
        "model.layers.21.self_attn.q_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true
        ],
        "model.layers.21.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.22.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true
        ],
        "model.layers.22.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true
        ],
        "model.layers.23.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.23.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true
        ],
        "model.layers.24.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true
        ],
        "model.layers.24.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.25.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.25.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.26.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.26.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.27.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.27.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true
        ]
      },
      "alpha_pattern": {},
      "megatron_config": null,
      "megatron_core": "megatron.core",
      "trainable_token_indices": null,
      "loftq_config": {},
      "eva_config": null,
      "corda_config": null,
      "use_dora": false,
      "alora_invocation_tokens": null,
      "use_qalora": false,
      "qalora_group_size": 16,
      "layer_replication": null,
      "lora_bias": false,
      "target_parameters": null,
      "use_bdlora": null,
      "arrow_config": null,
      "ensure_weight_tying": false,
      "target_r": 32,
      "init_r": 64,
      "tinit": 200,
      "tfinal": 500,
      "deltaT": 1,
      "beta1": 0.85,
      "beta2": 0.85,
      "orth_reg_weight": 0.5,
      "total_step": 5000
    },
    "error_msg": ""
  },
  "train_info": {
    "accelerator_memory_reserved_avg": 14915761654,
    "accelerator_memory_max": 22796042240,
    "accelerator_memory_reserved_99th": 20617101312,
    "train_time": 1097.5522341161268,
    "file_size": 35131056,
    "num_trainable_params": 18353664,
    "num_total_params": 3231103544,
    "status": "success",
    "metrics": [
      {
        "step": 250,
        "valid accuracy": 0.0,
        "train loss": 1.3241328690052032,
        "train samples": 1000,
        "train time": 33.437529707327485,
        "eval time": 12.192411294032354,
        "tokens / sec": 6331.777552143872,
        "mem allocated avg": 7294713141.248,
        "mem reserved avg": 15068431384.576,
        "elapsed time": 71.46285747201182
      },
      {
        "step": 500,
        "valid accuracy": 0.42,
        "train loss": 1.0195916182994842,
        "train samples": 2000,
        "train time": 35.78730485920096,
        "eval time": 12.20008662098553,
        "tokens / sec": 5811.977203042275,
        "mem allocated avg": 7287517972.48,
        "mem reserved avg": 14679560683.52,
        "elapsed time": 123.03286996803945
      },
      {
        "step": 750,
        "valid accuracy": 0.3,
        "train loss": 0.788285866856575,
        "train samples": 3000,
        "train time": 36.553958278673235,
        "eval time": 12.192845579993445,
        "tokens / sec": 5865.329230982038,
        "mem allocated avg": 7297823625.216,
        "mem reserved avg": 14887958872.064,
        "elapsed time": 175.27128310705302
      },
      {
        "step": 1000,
        "valid accuracy": 0.34,
        "train loss": 0.7407853524684906,
        "train samples": 4000,
        "train time": 36.186631593853235,
        "eval time": 12.179883008997422,
        "tokens / sec": 5757.264238857439,
        "mem allocated avg": 7288626950.144,
        "mem reserved avg": 14961325637.632,
        "elapsed time": 227.3045465090545
      },
      {
        "step": 1250,
        "valid accuracy": 0.32,
        "train loss": 0.7283406076431275,
        "train samples": 5000,
        "train time": 35.77542787248967,
        "eval time": 12.210806805000175,
        "tokens / sec": 5829.084721034463,
        "mem allocated avg": 7289293629.44,
        "mem reserved avg": 14984788574.208,
        "elapsed time": 278.867415188055
      },
      {
        "step": 1500,
        "valid accuracy": 0.38,
        "train loss": 0.7160038756132125,
        "train samples": 6000,
        "train time": 35.90073716780171,
        "eval time": 12.185589247965254,
        "tokens / sec": 5830.827345454697,
        "mem allocated avg": 7291158284.288,
        "mem reserved avg": 14897169563.648,
        "elapsed time": 330.540843091032
      },
      {
        "step": 1750,
        "valid accuracy": 0.34,
        "train loss": 0.7057664946317673,
        "train samples": 7000,
        "train time": 35.91021893679863,
        "eval time": 12.154321324953344,
        "tokens / sec": 5829.95610158939,
        "mem allocated avg": 7292672542.72,
        "mem reserved avg": 15298061139.968,
        "elapsed time": 382.3315215060138
      },
      {
        "step": 2000,
        "valid accuracy": 0.34,
        "train loss": 0.7058077181577682,
        "train samples": 8000,
        "train time": 35.90797309036134,
        "eval time": 12.198829908971675,
        "tokens / sec": 5784.119295103047,
        "mem allocated avg": 7288192765.952,
        "mem reserved avg": 14933509013.504,
        "elapsed time": 434.1038082460291
      },
      {
        "step": 2250,
        "valid accuracy": 0.36,
        "train loss": 0.6997898343801499,
        "train samples": 9000,
        "train time": 36.599770584725775,
        "eval time": 12.184865101007745,
        "tokens / sec": 5872.932987446225,
        "mem allocated avg": 7298940741.632,
        "mem reserved avg": 15212841271.296,
        "elapsed time": 486.43084904103307
      },
      {
        "step": 2500,
        "valid accuracy": 0.36,
        "train loss": 0.6983125779628754,
        "train samples": 10000,
        "train time": 35.72843996837037,
        "eval time": 7.310388852027245,
        "tokens / sec": 5764.791303016259,
        "mem allocated avg": 7285925011.456,
        "mem reserved avg": 14699911446.528,
        "elapsed time": 533.0108368530055
      },
      {
        "step": 2750,
        "valid accuracy": 0.32,
        "train loss": 0.6912899543046951,
        "train samples": 11000,
        "train time": 36.1996374403825,
        "eval time": 12.285541804973036,
        "tokens / sec": 5853.124920075475,
        "mem allocated avg": 7295115497.472,
        "mem reserved avg": 15075444260.864,
        "elapsed time": 585.0133225410245
      },
      {
        "step": 3000,
        "valid accuracy": 0.36,
        "train loss": 0.6850721148252488,
        "train samples": 12000,
        "train time": 35.86890918528661,
        "eval time": 12.206184039998334,
        "tokens / sec": 5819.2737036347135,
        "mem allocated avg": 7291246731.264,
        "mem reserved avg": 15016489123.84,
        "elapsed time": 636.763230385026
      },
      {
        "step": 3250,
        "valid accuracy": 0.34,
        "train loss": 0.6939100304841995,
        "train samples": 13000,
        "train time": 36.13155907928012,
        "eval time": 12.18468267400749,
        "tokens / sec": 5837.030157963555,
        "mem allocated avg": 7293795069.952,
        "mem reserved avg": 14881256374.272,
        "elapsed time": 688.5670087640174
      },
      {
        "step": 3500,
        "valid accuracy": 0.36,
        "train loss": 0.6824952847957612,
        "train samples": 14000,
        "train time": 35.909013247233815,
        "eval time": 12.309029697033111,
        "tokens / sec": 5841.151873371449,
        "mem allocated avg": 7290872406.016,
        "mem reserved avg": 14875896053.76,
        "elapsed time": 740.3315773730283
      },
      {
        "step": 3750,
        "valid accuracy": 0.32,
        "train loss": 0.6794799867868423,
        "train samples": 15000,
        "train time": 36.30529697693419,
        "eval time": 12.151031351007987,
        "tokens / sec": 5968.908617871319,
        "mem allocated avg": 7301860868.096,
        "mem reserved avg": 15216507092.992,
        "elapsed time": 792.3454526530113
      },
      {
        "step": 4000,
        "valid accuracy": 0.3,
        "train loss": 0.6966380437612534,
        "train samples": 16000,
        "train time": 35.68916123179952,
        "eval time": 12.212951252993662,
        "tokens / sec": 5726.472490418209,
        "mem allocated avg": 7282899265.536,
        "mem reserved avg": 14899249938.432,
        "elapsed time": 843.872047640034
      },
      {
        "step": 4250,
        "valid accuracy": 0.32,
        "train loss": 0.6774853245019913,
        "train samples": 17000,
        "train time": 36.08229462581221,
        "eval time": 12.197503683972172,
        "tokens / sec": 5858.524303739224,
        "mem allocated avg": 7294883461.12,
        "mem reserved avg": 14887791099.904,
        "elapsed time": 895.6108071450144
      },
      {
        "step": 4500,
        "valid accuracy": 0.32,
        "train loss": 0.6867766143083572,
        "train samples": 18000,
        "train time": 35.802349225094076,
        "eval time": 12.20918653300032,
        "tokens / sec": 5804.591165049559,
        "mem allocated avg": 7287909275.648,
        "mem reserved avg": 14847987154.944,
        "elapsed time": 947.2645250619971
      },
      {
        "step": 4750,
        "valid accuracy": 0.32,
        "train loss": 0.6804986503124237,
        "train samples": 19000,
        "train time": 32.32421511563007,
        "eval time": 12.151784093992319,
        "tokens / sec": 6494.790337491783,
        "mem allocated avg": 7071402708.992,
        "mem reserved avg": 14653581164.544,
        "elapsed time": 995.2198103830451
      },
      {
        "step": 5000,
        "valid accuracy": 0.34,
        "train loss": 0.6861251518726349,
        "train samples": 20000,
        "train time": 31.86748417984927,
        "eval time": 12.234077127010096,
        "tokens / sec": 6535.815592612781,
        "mem allocated avg": 7067250501.632,
        "mem reserved avg": 14337473249.28,
        "elapsed time": 1042.8103677670006
      },
      {
        "step": 5000,
        "test accuracy": 0.38362395754359363,
        "train loss": 0.6861251518726349,
        "train samples": 20000,
        "train total tokens": 4198051,
        "forgetting": 0.0754537582397461
      }
    ]
  },
  "meta_info": {
    "model_info": {
      "sha": "13afe5124825b4f3751f836b40dafda64c1ed062",
      "created_at": "2024-09-18T15:23:48+00:00"
    },
    "dataset_info": {
      "metamath": {
        "sha": "aa4f34d3d2d3231299b5b03d9b3e5a20da45aa18",
        "created_at": "2023-09-21T17:22:46+00:00"
      },
      "gsm8k": {
        "sha": "cc7b047b6e5bb11b4f1af84efc572db110a51b3c",
        "created_at": "2022-04-12T10:22:10+00:00"
      }
    },
    "package_info": {
      "transformers-version": "4.57.1",
      "transformers-commit-hash": null,
      "peft-version": "0.18.1.dev0",
      "peft-commit-hash": "8be1a16f5e06ca5e197d2af74bdfc5b3c8072d26",
      "datasets-version": "4.2.0",
      "datasets-commit-hash": null,
      "bitsandbytes-version": "0.46.0",
      "bitsandbytes-commit-hash": null,
      "torch-version": "2.9.0+cu128",
      "torch-commit-hash": null
    },
    "system_info": {
      "system": "Linux",
      "release": "6.14.0-1016-aws",
      "version": "#16~24.04.1-Ubuntu SMP Tue Oct 14 02:15:09 UTC 2025",
      "machine": "x86_64",
      "processor": "x86_64",
      "accelerator": "NVIDIA L40S"
    },
    "pytorch_info": "PyTorch built with:\n  - GCC 13.3\n  - C++ Version: 201703\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 12.8\n  - NVCC architecture flags: -gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_100,code=sm_100;-gencode;arch=compute_120,code=sm_120\n  - CuDNN 90.7.1\n    - Built with CuDNN 90.8\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=0fabc3ba44823f257e70ce397d989c8de5e362c1, CUDA_VERSION=12.8, CUDNN_VERSION=9.8.0, CXX_COMPILER=/opt/rh/gcc-toolset-13/root/usr/bin/c++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -DC10_NODEPRECATED -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-dangling-reference -Wno-error=dangling-reference -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, \n"
  }
}