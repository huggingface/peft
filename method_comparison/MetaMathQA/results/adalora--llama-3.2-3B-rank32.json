{
  "run_info": {
    "created_at": "2026-01-06T23:09:50+00:00",
    "total_time": 1335.4632956469868,
    "experiment_name": "adalora/llama-3.2-3B-rank32",
    "peft_branch": "main",
    "train_config": {
      "model_id": "meta-llama/Llama-3.2-3B",
      "dtype": "bfloat16",
      "max_seq_length": 768,
      "batch_size": 4,
      "batch_size_eval": 50,
      "max_steps": 5000,
      "eval_steps": 250,
      "compile": false,
      "query_template": "Question: {query} Think step by step.\nAnswer:",
      "seed": 0,
      "grad_norm_clip": 1.0,
      "optimizer_type": "AdamW",
      "optimizer_kwargs": {
        "lr": 0.0001,
        "weight_decay": 0.1
      },
      "lr_scheduler": "cosine",
      "use_amp": false,
      "autocast_adapter_dtype": true,
      "generation_kwargs": {
        "max_length": 800,
        "max_new_tokens": 300
      },
      "attn_implementation": null
    },
    "peft_config": {
      "task_type": null,
      "peft_type": "ADALORA",
      "auto_mapping": null,
      "peft_version": "0.18.1.dev0@UNKNOWN",
      "base_model_name_or_path": "meta-llama/Llama-3.2-3B",
      "revision": null,
      "inference_mode": false,
      "r": 8,
      "target_modules": [
        "q_proj",
        "v_proj"
      ],
      "exclude_modules": null,
      "lora_alpha": 8,
      "lora_dropout": 0.0,
      "fan_in_fan_out": false,
      "bias": "none",
      "use_rslora": false,
      "modules_to_save": null,
      "init_lora_weights": true,
      "layers_to_transform": null,
      "layers_pattern": null,
      "rank_pattern": {
        "model.layers.0.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.0.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.1.self_attn.q_proj.lora_E": [
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false
        ],
        "model.layers.1.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.2.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false
        ],
        "model.layers.2.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true
        ],
        "model.layers.3.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.3.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true
        ],
        "model.layers.4.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.4.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.5.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.5.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true
        ],
        "model.layers.6.self_attn.q_proj.lora_E": [
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.6.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true
        ],
        "model.layers.7.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.7.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true
        ],
        "model.layers.8.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.8.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.9.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true
        ],
        "model.layers.9.self_attn.v_proj.lora_E": [
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.10.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.10.self_attn.v_proj.lora_E": [
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true
        ],
        "model.layers.11.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false
        ],
        "model.layers.11.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.12.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.12.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false
        ],
        "model.layers.13.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.13.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.14.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.14.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false
        ],
        "model.layers.15.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.15.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.16.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.16.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false
        ],
        "model.layers.17.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.17.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.18.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true
        ],
        "model.layers.18.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true
        ],
        "model.layers.19.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true
        ],
        "model.layers.19.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.20.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.20.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true
        ],
        "model.layers.21.self_attn.q_proj.lora_E": [
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.21.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.22.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true
        ],
        "model.layers.22.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.23.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.23.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true
        ],
        "model.layers.24.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true
        ],
        "model.layers.24.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.25.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.25.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.26.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.26.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.27.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.27.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true
        ]
      },
      "alpha_pattern": {},
      "megatron_config": null,
      "megatron_core": "megatron.core",
      "trainable_token_indices": null,
      "loftq_config": {},
      "eva_config": null,
      "corda_config": null,
      "use_dora": false,
      "alora_invocation_tokens": null,
      "use_qalora": false,
      "qalora_group_size": 16,
      "layer_replication": null,
      "lora_bias": false,
      "target_parameters": null,
      "use_bdlora": null,
      "arrow_config": null,
      "ensure_weight_tying": false,
      "target_r": 32,
      "init_r": 64,
      "tinit": 200,
      "tfinal": 500,
      "deltaT": 1,
      "beta1": 0.85,
      "beta2": 0.85,
      "orth_reg_weight": 0.5,
      "total_step": 5000
    },
    "error_msg": ""
  },
  "train_info": {
    "accelerator_memory_reserved_avg": 14916106846,
    "accelerator_memory_max": 22796042240,
    "accelerator_memory_reserved_99th": 20617101312,
    "train_time": 1096.985978747005,
    "file_size": 35106480,
    "num_trainable_params": 18353664,
    "num_total_params": 3231103544,
    "status": "success",
    "metrics": [
      {
        "step": 250,
        "valid accuracy": 0.0,
        "train loss": 1.324140142440796,
        "train samples": 1000,
        "train time": 33.500183526062756,
        "eval time": 12.220312830002513,
        "tokens / sec": 6319.935526182568,
        "mem allocated avg": 7294694856.704,
        "mem reserved avg": 15068112617.472,
        "elapsed time": 68.53489957899728
      },
      {
        "step": 500,
        "valid accuracy": 0.42,
        "train loss": 1.0195122983455658,
        "train samples": 2000,
        "train time": 35.60108946581022,
        "eval time": 12.190234194989898,
        "tokens / sec": 5842.377385662582,
        "mem allocated avg": 7287478896.64,
        "mem reserved avg": 14680659591.168,
        "elapsed time": 119.88873759200214
      },
      {
        "step": 750,
        "valid accuracy": 0.32,
        "train loss": 0.7882970356941223,
        "train samples": 3000,
        "train time": 36.321435723031755,
        "eval time": 7.283175233009388,
        "tokens / sec": 5902.877893784534,
        "mem allocated avg": 7297866846.208,
        "mem reserved avg": 14906187317.248,
        "elapsed time": 166.95069194000098
      },
      {
        "step": 1000,
        "valid accuracy": 0.36,
        "train loss": 0.7408353788852692,
        "train samples": 4000,
        "train time": 36.16941774800944,
        "eval time": 12.211646334995748,
        "tokens / sec": 5760.004251422202,
        "mem allocated avg": 7288718004.224,
        "mem reserved avg": 14960126066.688,
        "elapsed time": 218.99036621800042
      },
      {
        "step": 1250,
        "valid accuracy": 0.32,
        "train loss": 0.728391561627388,
        "train samples": 5000,
        "train time": 35.598788590184995,
        "eval time": 12.20358876499813,
        "tokens / sec": 5858.008327213033,
        "mem allocated avg": 7289340125.184,
        "mem reserved avg": 14980476829.696,
        "elapsed time": 270.34009014599724
      },
      {
        "step": 1500,
        "valid accuracy": 0.38,
        "train loss": 0.7160676553249359,
        "train samples": 6000,
        "train time": 36.10844833898591,
        "eval time": 12.196739090999472,
        "tokens / sec": 5797.285943577574,
        "mem allocated avg": 7291119859.712,
        "mem reserved avg": 14893436633.088,
        "elapsed time": 322.21822101699945
      },
      {
        "step": 1750,
        "valid accuracy": 0.38,
        "train loss": 0.7056208809614182,
        "train samples": 7000,
        "train time": 36.31575935892761,
        "eval time": 12.219781122999848,
        "tokens / sec": 5764.85260657323,
        "mem allocated avg": 7292606658.56,
        "mem reserved avg": 15295242567.68,
        "elapsed time": 374.46384709900303
      },
      {
        "step": 2000,
        "valid accuracy": 0.3,
        "train loss": 0.7058616338968277,
        "train samples": 8000,
        "train time": 35.938873685052386,
        "eval time": 12.233592098011286,
        "tokens / sec": 5779.1460528264815,
        "mem allocated avg": 7288242311.168,
        "mem reserved avg": 14930707218.432,
        "elapsed time": 426.28678846200637
      },
      {
        "step": 2250,
        "valid accuracy": 0.36,
        "train loss": 0.699912279009819,
        "train samples": 9000,
        "train time": 36.76531416318903,
        "eval time": 12.199453934998019,
        "tokens / sec": 5846.488868445871,
        "mem allocated avg": 7298980415.488,
        "mem reserved avg": 15212639944.704,
        "elapsed time": 478.7917722370039
      },
      {
        "step": 2500,
        "valid accuracy": 0.3,
        "train loss": 0.6983506038188935,
        "train samples": 10000,
        "train time": 35.82416073138302,
        "eval time": 12.17551254699356,
        "tokens / sec": 5749.38800505009,
        "mem allocated avg": 7285941215.232,
        "mem reserved avg": 14711185735.68,
        "elapsed time": 530.3331108140119
      },
      {
        "step": 2750,
        "valid accuracy": 0.32,
        "train loss": 0.6913313969373703,
        "train samples": 11000,
        "train time": 36.19878267814056,
        "eval time": 8.25128805800341,
        "tokens / sec": 5853.263129976717,
        "mem allocated avg": 7295112105.984,
        "mem reserved avg": 15087456747.52,
        "elapsed time": 578.3172669940104
      },
      {
        "step": 3000,
        "valid accuracy": 0.34,
        "train loss": 0.6851036378145218,
        "train samples": 12000,
        "train time": 36.35608197198599,
        "eval time": 12.152376512996852,
        "tokens / sec": 5741.295229800525,
        "mem allocated avg": 7291224719.36,
        "mem reserved avg": 15015843201.024,
        "elapsed time": 630.5229358540091
      },
      {
        "step": 3250,
        "valid accuracy": 0.34,
        "train loss": 0.6938701298236847,
        "train samples": 13000,
        "train time": 35.73065986999427,
        "eval time": 12.144776845001616,
        "tokens / sec": 5902.521833276006,
        "mem allocated avg": 7293882863.616,
        "mem reserved avg": 14881432535.04,
        "elapsed time": 681.9050700060034
      },
      {
        "step": 3500,
        "valid accuracy": 0.4,
        "train loss": 0.68247136926651,
        "train samples": 14000,
        "train time": 36.00635994208278,
        "eval time": 12.326363198983017,
        "tokens / sec": 5825.359751371387,
        "mem allocated avg": 7290826170.368,
        "mem reserved avg": 14875183022.08,
        "elapsed time": 733.786312968994
      },
      {
        "step": 3750,
        "valid accuracy": 0.34,
        "train loss": 0.6794179630279541,
        "train samples": 15000,
        "train time": 36.57572074487689,
        "eval time": 12.198553194000851,
        "tokens / sec": 5924.777299989455,
        "mem allocated avg": 7301837856.768,
        "mem reserved avg": 15217270456.32,
        "elapsed time": 786.1127500809962
      },
      {
        "step": 4000,
        "valid accuracy": 0.3,
        "train loss": 0.6966168670654297,
        "train samples": 16000,
        "train time": 35.97871255094651,
        "eval time": 12.18804284799262,
        "tokens / sec": 5680.386692842444,
        "mem allocated avg": 7282981027.84,
        "mem reserved avg": 14899308658.688,
        "elapsed time": 837.9084427909984
      },
      {
        "step": 4250,
        "valid accuracy": 0.34,
        "train loss": 0.6775666291713714,
        "train samples": 17000,
        "train time": 36.241603212227346,
        "eval time": 12.189591965987347,
        "tokens / sec": 5832.771766804198,
        "mem allocated avg": 7294902335.488,
        "mem reserved avg": 14890081189.888,
        "elapsed time": 889.8094875199895
      },
      {
        "step": 4500,
        "valid accuracy": 0.3,
        "train loss": 0.6867989786863327,
        "train samples": 18000,
        "train time": 35.93566888789064,
        "eval time": 12.240233601012733,
        "tokens / sec": 5783.056401380331,
        "mem allocated avg": 7287897069.568,
        "mem reserved avg": 14833911070.72,
        "elapsed time": 941.618901445996
      },
      {
        "step": 4750,
        "valid accuracy": 0.32,
        "train loss": 0.6805637099742889,
        "train samples": 19000,
        "train time": 32.28778368287021,
        "eval time": 12.209750720008742,
        "tokens / sec": 6502.118636014646,
        "mem allocated avg": 7071502667.776,
        "mem reserved avg": 14658949873.664,
        "elapsed time": 989.6039193939941
      },
      {
        "step": 5000,
        "valid accuracy": 0.28,
        "train loss": 0.6862391360998154,
        "train samples": 20000,
        "train time": 31.97296128119342,
        "eval time": 12.261744646006264,
        "tokens / sec": 6514.254284056911,
        "mem allocated avg": 7067358873.6,
        "mem reserved avg": 14323925647.36,
        "elapsed time": 1037.3070829329954
      },
      {
        "step": 5000,
        "test accuracy": 0.3904473085670963,
        "train loss": 0.6862391360998154,
        "train samples": 20000,
        "train total tokens": 4198051,
        "forgetting": 0.04797172546386719
      }
    ]
  },
  "meta_info": {
    "model_info": {
      "sha": "13afe5124825b4f3751f836b40dafda64c1ed062",
      "created_at": "2024-09-18T15:23:48+00:00"
    },
    "dataset_info": {
      "metamath": {
        "sha": "aa4f34d3d2d3231299b5b03d9b3e5a20da45aa18",
        "created_at": "2023-09-21T17:22:46+00:00"
      },
      "gsm8k": {
        "sha": "cc7b047b6e5bb11b4f1af84efc572db110a51b3c",
        "created_at": "2022-04-12T10:22:10+00:00"
      }
    },
    "package_info": {
      "transformers-version": "4.57.1",
      "transformers-commit-hash": null,
      "peft-version": "0.18.1.dev0",
      "peft-commit-hash": "261366de2e40cde64b702d6b9c527081ad850549",
      "datasets-version": "4.2.0",
      "datasets-commit-hash": null,
      "bitsandbytes-version": "0.46.0",
      "bitsandbytes-commit-hash": null,
      "torch-version": "2.9.0+cu128",
      "torch-commit-hash": null
    },
    "system_info": {
      "system": "Linux",
      "release": "6.14.0-1016-aws",
      "version": "#16~24.04.1-Ubuntu SMP Tue Oct 14 02:15:09 UTC 2025",
      "machine": "x86_64",
      "processor": "x86_64",
      "accelerator": "NVIDIA L40S"
    },
    "pytorch_info": "PyTorch built with:\n  - GCC 13.3\n  - C++ Version: 201703\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 12.8\n  - NVCC architecture flags: -gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_100,code=sm_100;-gencode;arch=compute_120,code=sm_120\n  - CuDNN 90.7.1\n    - Built with CuDNN 90.8\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=0fabc3ba44823f257e70ce397d989c8de5e362c1, CUDA_VERSION=12.8, CUDNN_VERSION=9.8.0, CXX_COMPILER=/opt/rh/gcc-toolset-13/root/usr/bin/c++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -DC10_NODEPRECATED -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-dangling-reference -Wno-error=dangling-reference -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, \n"
  }
}