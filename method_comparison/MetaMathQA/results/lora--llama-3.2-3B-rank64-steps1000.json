{
  "run_info": {
    "created_at": "2025-07-18T13:24:27+00:00",
    "total_time": 641.1107667809993,
    "experiment_name": "lora/llama-3.2-3B-rank64-steps1000",
    "peft_branch": "main",
    "train_config": {
      "model_id": "meta-llama/Llama-3.2-3B",
      "dtype": "bfloat16",
      "max_seq_length": 768,
      "batch_size": 4,
      "batch_size_eval": 50,
      "max_steps": 1000,
      "eval_steps": 250,
      "compile": false,
      "query_template": "Question: {query} Think step by step.\nAnswer:",
      "seed": 0,
      "grad_norm_clip": 1.0,
      "optimizer_type": "AdamW",
      "optimizer_kwargs": {
        "lr": 0.0001,
        "weight_decay": 0.1
      },
      "lr_scheduler": "cosine",
      "use_amp": false,
      "autocast_adapter_dtype": true,
      "generation_kwargs": {
        "max_length": 800,
        "max_new_tokens": 300
      },
      "attn_implementation": null,
      "fast_forward": false
    },
    "peft_config": {
      "task_type": "CAUSAL_LM",
      "peft_type": "LORA",
      "auto_mapping": null,
      "base_model_name_or_path": "meta-llama/Llama-3.2-3B",
      "revision": null,
      "inference_mode": false,
      "r": 64,
      "target_modules": [
        "v_proj",
        "q_proj"
      ],
      "exclude_modules": null,
      "lora_alpha": 128,
      "lora_dropout": 0.0,
      "fan_in_fan_out": false,
      "bias": "none",
      "use_rslora": false,
      "modules_to_save": null,
      "init_lora_weights": true,
      "layers_to_transform": null,
      "layers_pattern": null,
      "rank_pattern": {},
      "alpha_pattern": {},
      "megatron_config": null,
      "megatron_core": "megatron.core",
      "trainable_token_indices": null,
      "loftq_config": {},
      "eva_config": null,
      "corda_config": null,
      "use_dora": false,
      "use_qalora": false,
      "qalora_group_size": 16,
      "layer_replication": null,
      "lora_bias": false,
      "target_parameters": null
    },
    "error_msg": ""
  },
  "train_info": {
    "cuda_memory_reserved_avg": 12142684143,
    "cuda_memory_max": 20061356032,
    "cuda_memory_reserved_99th": 17607709163,
    "train_time": 597.7685309190128,
    "file_size": 73415408,
    "num_trainable_params": 18350080,
    "num_total_params": 3231099904,
    "status": "success",
    "metrics": [
      {
        "step": 250,
        "valid accuracy": 0.36,
        "train loss": 0.8284117395877838,
        "train samples": 1000,
        "train time": 31.63228438576334,
        "eval time": 11.165220341994427,
        "tokens / sec": 6693.130265839663,
        "mem allocated avg": 7072416421.888,
        "mem reserved avg": 12177616404.48,
        "elapsed time": 105.85056627000449
      },
      {
        "step": 500,
        "valid accuracy": 0.38,
        "train loss": 0.6840059629678726,
        "train samples": 2000,
        "train time": 31.348113200918306,
        "eval time": 11.122051310987445,
        "tokens / sec": 6635.008578248564,
        "mem allocated avg": 7065117136.896,
        "mem reserved avg": 12071844446.208,
        "elapsed time": 198.0022406290227
      },
      {
        "step": 750,
        "valid accuracy": 0.5,
        "train loss": 0.6551985988616943,
        "train samples": 3000,
        "train time": 31.90241910723853,
        "eval time": 6.518824605998816,
        "tokens / sec": 6720.52483792219,
        "mem allocated avg": 7075655270.4,
        "mem reserved avg": 12225985118.208,
        "elapsed time": 286.8869726470148
      },
      {
        "step": 1000,
        "valid accuracy": 0.46,
        "train loss": 0.6427994055747985,
        "train samples": 4000,
        "train time": 31.597787113219965,
        "eval time": 11.143998087005457,
        "tokens / sec": 6593.373113550595,
        "mem allocated avg": 7066149046.272,
        "mem reserved avg": 12095290605.568,
        "elapsed time": 379.4298628940014
      },
      {
        "step": 1000,
        "test accuracy": 0.4139499620924943,
        "train loss": 0.6427994055747985,
        "train samples": 4000,
        "train total tokens": 842451
      }
    ]
  },
  "meta_info": {
    "model_info": {
      "sha": "13afe5124825b4f3751f836b40dafda64c1ed062",
      "created_at": "2024-09-18T15:23:48+00:00"
    },
    "dataset_info": {
      "metamath": {
        "sha": "aa4f34d3d2d3231299b5b03d9b3e5a20da45aa18",
        "created_at": "2023-09-21T17:22:46+00:00"
      },
      "gsm8k": {
        "sha": "e53f048856ff4f594e959d75785d2c2d37b678ee",
        "created_at": "2022-04-12T10:22:10+00:00"
      }
    },
    "package_info": {
      "transformers-version": "4.52.4",
      "transformers-commit-hash": null,
      "peft-version": "0.16.1.dev0",
      "peft-commit-hash": "f3b97c370489ff480d00aaebda86bfbbf927a728",
      "datasets-version": "4.0.0",
      "datasets-commit-hash": null,
      "bitsandbytes-version": "0.46.0",
      "bitsandbytes-commit-hash": null,
      "torch-version": "2.7.1+cu126",
      "torch-commit-hash": null
    },
    "system_info": {
      "system": "Linux",
      "release": "6.8.0-1030-aws",
      "version": "#32-Ubuntu SMP Wed May 28 19:48:56 UTC 2025",
      "machine": "x86_64",
      "processor": "x86_64",
      "gpu": "NVIDIA L40S"
    },
    "pytorch_info": "PyTorch built with:\n  - GCC 11.2\n  - C++ Version: 201703\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 12.6\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n  - CuDNN 90.7.1  (built against CUDA 12.8)\n    - Built with CuDNN 90.5.1\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=e2d141dbde55c2a4370fac5165b0561b6af4798b, CUDA_VERSION=12.6, CUDNN_VERSION=9.5.1, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.7.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n"
  }
}