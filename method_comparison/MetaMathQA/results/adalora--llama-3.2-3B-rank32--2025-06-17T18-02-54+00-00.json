{
  "run_info": {
    "created_at": "2025-06-17T18:02:54+00:00",
    "total_time": 2570.095540000999,
    "experiment_name": "adalora/llama-3.2-3B-rank32",
    "peft_branch": "main",
    "train_config": {
      "model_id": "meta-llama/Llama-3.2-3B",
      "dtype": "bfloat16",
      "max_seq_length": 768,
      "batch_size": 4,
      "batch_size_eval": 50,
      "max_steps": 5000,
      "eval_steps": 250,
      "compile": false,
      "query_template": "Question: {query} Think step by step.\nAnswer:",
      "seed": 0,
      "grad_norm_clip": 1.0,
      "optimizer_type": "AdamW",
      "optimizer_kwargs": {
        "lr": 0.0001,
        "weight_decay": 0.1
      },
      "lr_scheduler": "cosine",
      "use_amp": false,
      "autocast_adapter_dtype": true,
      "generation_kwargs": {
        "max_length": 800,
        "max_new_tokens": 300
      },
      "attn_implementation": null
    },
    "peft_config": {
      "task_type": null,
      "peft_type": "ADALORA",
      "auto_mapping": null,
      "base_model_name_or_path": "meta-llama/Llama-3.2-3B",
      "revision": null,
      "inference_mode": false,
      "r": 8,
      "target_modules": [
        "q_proj",
        "v_proj"
      ],
      "exclude_modules": null,
      "lora_alpha": 8,
      "lora_dropout": 0.0,
      "fan_in_fan_out": false,
      "bias": "none",
      "use_rslora": false,
      "modules_to_save": null,
      "init_lora_weights": true,
      "layers_to_transform": null,
      "layers_pattern": null,
      "rank_pattern": {
        "model.layers.0.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.0.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.1.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true
        ],
        "model.layers.1.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.2.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false
        ],
        "model.layers.2.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.3.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.3.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true
        ],
        "model.layers.4.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false
        ],
        "model.layers.4.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.5.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.5.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true
        ],
        "model.layers.6.self_attn.q_proj.lora_E": [
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.6.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true
        ],
        "model.layers.7.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.7.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true
        ],
        "model.layers.8.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.8.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.9.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.9.self_attn.v_proj.lora_E": [
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.10.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.10.self_attn.v_proj.lora_E": [
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true
        ],
        "model.layers.11.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false
        ],
        "model.layers.11.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false
        ],
        "model.layers.12.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.12.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false
        ],
        "model.layers.13.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.13.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.14.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.14.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.15.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.15.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.16.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true
        ],
        "model.layers.16.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false
        ],
        "model.layers.17.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
        ],
        "model.layers.17.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.18.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.18.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true
        ],
        "model.layers.19.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.19.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.20.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.20.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true
        ],
        "model.layers.21.self_attn.q_proj.lora_E": [
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.21.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true
        ],
        "model.layers.22.self_attn.q_proj.lora_E": [
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true
        ],
        "model.layers.22.self_attn.v_proj.lora_E": [
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.23.self_attn.q_proj.lora_E": [
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true
        ],
        "model.layers.23.self_attn.v_proj.lora_E": [
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true
        ],
        "model.layers.24.self_attn.q_proj.lora_E": [
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true
        ],
        "model.layers.24.self_attn.v_proj.lora_E": [
          true,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true
        ],
        "model.layers.25.self_attn.q_proj.lora_E": [
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.25.self_attn.v_proj.lora_E": [
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false
        ],
        "model.layers.26.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true
        ],
        "model.layers.26.self_attn.v_proj.lora_E": [
          false,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          false,
          true,
          false,
          false,
          false,
          true,
          false,
          false
        ],
        "model.layers.27.self_attn.q_proj.lora_E": [
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          false,
          true,
          false
        ],
        "model.layers.27.self_attn.v_proj.lora_E": [
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          false,
          false,
          true,
          true,
          false,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          false,
          false,
          true,
          false,
          true,
          true,
          true,
          false,
          false,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          false,
          true
        ]
      },
      "alpha_pattern": {},
      "megatron_config": null,
      "megatron_core": "megatron.core",
      "trainable_token_indices": null,
      "loftq_config": {},
      "eva_config": null,
      "corda_config": null,
      "use_dora": false,
      "layer_replication": null,
      "lora_bias": false,
      "target_r": 32,
      "init_r": 64,
      "tinit": 200,
      "tfinal": 500,
      "deltaT": 1,
      "beta1": 0.85,
      "beta2": 0.85,
      "orth_reg_weight": 0.5,
      "total_step": 5000
    }
  },
  "train_info": {
    "cuda_memory_reserved_avg": 12361481689,
    "cuda_memory_max": 22793945088,
    "cuda_memory_reserved_99th": 18203426160,
    "train_time": 2337.1537621740026,
    "file_size": 35090096,
    "status": "success",
    "metrics": [
      {
        "step": 250,
        "valid accuracy": 0.0,
        "train loss": 1.3241328556537628,
        "train samples": 1000,
        "loss avg": 1.3241328556537628,
        "train time": 47.97327231703457,
        "eval time": 11.621217741998407,
        "tokens / sec": 4413.269926655011,
        "mem allocated avg": 7292959393.792,
        "mem reserved avg": 12441731727.36,
        "elapsed time": 118.80749342100171
      },
      {
        "step": 500,
        "valid accuracy": 0.4,
        "train loss": 1.0196672148704529,
        "train samples": 2000,
        "loss avg": 1.0196672148704529,
        "train time": 49.531776828040165,
        "eval time": 11.541516762001265,
        "tokens / sec": 4199.223474701862,
        "mem allocated avg": 7285510731.776,
        "mem reserved avg": 12328493907.968,
        "elapsed time": 234.03294430200185
      },
      {
        "step": 750,
        "valid accuracy": 0.32,
        "train loss": 0.7884338703155518,
        "train samples": 3000,
        "loss avg": 0.7884338703155518,
        "train time": 49.71748925202701,
        "eval time": 11.448882871998649,
        "tokens / sec": 4312.385907364756,
        "mem allocated avg": 7296095842.304,
        "mem reserved avg": 12484438130.688,
        "elapsed time": 350.6772116690008
      },
      {
        "step": 1000,
        "valid accuracy": 0.32,
        "train loss": 0.740910219669342,
        "train samples": 4000,
        "loss avg": 0.740910219669342,
        "train time": 49.026840832018934,
        "eval time": 11.812752240999544,
        "tokens / sec": 4249.427384355099,
        "mem allocated avg": 7286506670.08,
        "mem reserved avg": 12351948455.936,
        "elapsed time": 466.5684357140017
      },
      {
        "step": 1250,
        "valid accuracy": 0.36,
        "train loss": 0.728336424946785,
        "train samples": 5000,
        "loss avg": 0.728336424946785,
        "train time": 48.04545661899465,
        "eval time": 11.868630412998755,
        "tokens / sec": 4340.43122232613,
        "mem allocated avg": 7287005519.872,
        "mem reserved avg": 12349910024.192,
        "elapsed time": 581.1975228129995
      },
      {
        "step": 1500,
        "valid accuracy": 0.4,
        "train loss": 0.7160347049236298,
        "train samples": 6000,
        "loss avg": 0.7160347049236298,
        "train time": 48.86433691299317,
        "eval time": 11.796965995999926,
        "tokens / sec": 4283.921837980334,
        "mem allocated avg": 7287642494.976,
        "mem reserved avg": 12380570386.432,
        "elapsed time": 696.8467505000008
      },
      {
        "step": 1750,
        "valid accuracy": 0.32,
        "train loss": 0.7056518207788467,
        "train samples": 7000,
        "loss avg": 0.7056518207788467,
        "train time": 49.11503971997445,
        "eval time": 11.31584956700317,
        "tokens / sec": 4262.543636198222,
        "mem allocated avg": 7289782888.448,
        "mem reserved avg": 12389051269.12,
        "elapsed time": 811.4924316569995
      },
      {
        "step": 2000,
        "valid accuracy": 0.32,
        "train loss": 0.7058726091384888,
        "train samples": 8000,
        "loss avg": 0.7058726091384888,
        "train time": 48.38644057898273,
        "eval time": 11.75540032400022,
        "tokens / sec": 4292.442211387118,
        "mem allocated avg": 7287054886.912,
        "mem reserved avg": 12336119152.64,
        "elapsed time": 925.7942195620017
      },
      {
        "step": 2250,
        "valid accuracy": 0.34,
        "train loss": 0.6999002494812012,
        "train samples": 9000,
        "loss avg": 0.6999002494812012,
        "train time": 49.39888451496881,
        "eval time": 11.50676274899888,
        "tokens / sec": 4351.272343707814,
        "mem allocated avg": 7297638139.904,
        "mem reserved avg": 12521129902.08,
        "elapsed time": 1042.426028662001
      },
      {
        "step": 2500,
        "valid accuracy": 0.34,
        "train loss": 0.6983108657598496,
        "train samples": 10000,
        "loss avg": 0.6983108657598496,
        "train time": 49.40858003895846,
        "eval time": 11.833392756998364,
        "tokens / sec": 4168.64843793519,
        "mem allocated avg": 7283608303.616,
        "mem reserved avg": 12278598467.584,
        "elapsed time": 1157.7294555840017
      },
      {
        "step": 2750,
        "valid accuracy": 0.32,
        "train loss": 0.691296777844429,
        "train samples": 11000,
        "loss avg": 0.691296777844429,
        "train time": 48.435872142017615,
        "eval time": 7.542235349003022,
        "tokens / sec": 4374.464433689745,
        "mem allocated avg": 7293332232.192,
        "mem reserved avg": 12452821467.136,
        "elapsed time": 1269.7437794450016
      },
      {
        "step": 3000,
        "valid accuracy": 0.34,
        "train loss": 0.6850603311061859,
        "train samples": 12000,
        "loss avg": 0.6850603311061859,
        "train time": 49.47394514003827,
        "eval time": 11.828584123999462,
        "tokens / sec": 4219.008599560381,
        "mem allocated avg": 7288929478.656,
        "mem reserved avg": 12371468746.752,
        "elapsed time": 1385.0191284909997
      },
      {
        "step": 3250,
        "valid accuracy": 0.36,
        "train loss": 0.6940460268259049,
        "train samples": 13000,
        "loss avg": 0.6940460268259049,
        "train time": 49.29976728300244,
        "eval time": 11.623199912002747,
        "tokens / sec": 4277.930944163187,
        "mem allocated avg": 7290687285.248,
        "mem reserved avg": 12403068633.088,
        "elapsed time": 1500.424247324001
      },
      {
        "step": 3500,
        "valid accuracy": 0.36,
        "train loss": 0.6826009773015976,
        "train samples": 14000,
        "loss avg": 0.6826009773015976,
        "train time": 49.202251872022316,
        "eval time": 12.043756905997725,
        "tokens / sec": 4263.016264897204,
        "mem allocated avg": 7289277476.864,
        "mem reserved avg": 12381820289.024,
        "elapsed time": 1616.5218509939987
      },
      {
        "step": 3750,
        "valid accuracy": 0.36,
        "train loss": 0.6794272404909134,
        "train samples": 15000,
        "loss avg": 0.6794272404909134,
        "train time": 48.70572795397311,
        "eval time": 11.443635993000498,
        "tokens / sec": 4449.230287755564,
        "mem allocated avg": 7299185600.512,
        "mem reserved avg": 12562561236.992,
        "elapsed time": 1733.8988631159991
      },
      {
        "step": 4000,
        "valid accuracy": 0.32,
        "train loss": 0.6965938065052032,
        "train samples": 16000,
        "loss avg": 0.6965938065052032,
        "train time": 48.49809504195582,
        "eval time": 11.836940927998512,
        "tokens / sec": 4214.0418056254875,
        "mem allocated avg": 7281535514.624,
        "mem reserved avg": 12256066666.496,
        "elapsed time": 1848.3159487509984
      },
      {
        "step": 4250,
        "valid accuracy": 0.36,
        "train loss": 0.6775380268096923,
        "train samples": 17000,
        "loss avg": 0.6775380268096923,
        "train time": 49.109756691043,
        "eval time": 11.43020573299873,
        "tokens / sec": 4304.419615227999,
        "mem allocated avg": 7291894349.824,
        "mem reserved avg": 12418562392.064,
        "elapsed time": 1963.5877769319995
      },
      {
        "step": 4500,
        "valid accuracy": 0.36,
        "train loss": 0.6867970683574677,
        "train samples": 18000,
        "loss avg": 0.6867970683574677,
        "train time": 48.05689006695684,
        "eval time": 11.978264322999166,
        "tokens / sec": 4324.416326367577,
        "mem allocated avg": 7285549684.736,
        "mem reserved avg": 12333837451.264,
        "elapsed time": 2078.717402442002
      },
      {
        "step": 4750,
        "valid accuracy": 0.36,
        "train loss": 0.6805349571704864,
        "train samples": 19000,
        "loss avg": 0.6805349571704864,
        "train time": 45.42010059905806,
        "eval time": 11.586666915001842,
        "tokens / sec": 4622.160612395337,
        "mem allocated avg": 7068488509.44,
        "mem reserved avg": 12120833916.928,
        "elapsed time": 2191.061481740002
      },
      {
        "step": 5000,
        "valid accuracy": 0.34,
        "train loss": 0.6862372272014617,
        "train samples": 20000,
        "loss avg": 0.6862372272014617,
        "train time": 45.248053363007784,
        "eval time": 11.688603310998587,
        "tokens / sec": 4603.070950457237,
        "mem allocated avg": 7065419485.184,
        "mem reserved avg": 12066601566.208,
        "elapsed time": 2302.9987963329986
      },
      {
        "step": 5000,
        "test accuracy": 0.38968915845337376,
        "train loss": 0.6862372272014617,
        "train samples": 20000,
        "train total tokens": 4198051
      }
    ]
  },
  "meta_info": {
    "model_info": {
      "sha": "13afe5124825b4f3751f836b40dafda64c1ed062",
      "created_at": "2024-09-18T15:23:48+00:00"
    },
    "dataset_info": {
      "metamath": {
        "sha": "aa4f34d3d2d3231299b5b03d9b3e5a20da45aa18",
        "created_at": "2023-09-21T17:22:46+00:00"
      },
      "gsm8k": {
        "sha": "e53f048856ff4f594e959d75785d2c2d37b678ee",
        "created_at": "2022-04-12T10:22:10+00:00"
      }
    },
    "package_info": {
      "transformers-version": "4.52.4",
      "transformers-commit-hash": null,
      "peft-version": "0.15.2.dev0",
      "peft-commit-hash": "a27406c26da0a1a4ceba2a98ac85c94e30824694",
      "datasets-version": "3.6.0",
      "datasets-commit-hash": null,
      "bitsandbytes-version": "0.46.0",
      "bitsandbytes-commit-hash": null,
      "torch-version": "2.7.1+cu126",
      "torch-commit-hash": null
    },
    "system_info": {
      "system": "Linux",
      "release": "6.8.0-1029-aws",
      "version": "#31-Ubuntu SMP Wed Apr 23 18:42:41 UTC 2025",
      "machine": "x86_64",
      "processor": "x86_64",
      "gpu": "NVIDIA L40S"
    },
    "pytorch_info": "PyTorch built with:\n  - GCC 11.2\n  - C++ Version: 201703\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 12.6\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n  - CuDNN 90.7.1  (built against CUDA 12.8)\n    - Built with CuDNN 90.5.1\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=e2d141dbde55c2a4370fac5165b0561b6af4798b, CUDA_VERSION=12.6, CUDNN_VERSION=9.5.1, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.7.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n"
  }
}